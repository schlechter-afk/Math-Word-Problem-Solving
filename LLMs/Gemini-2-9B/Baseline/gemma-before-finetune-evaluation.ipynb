{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T08:26:52.063829Z","iopub.status.busy":"2024-11-12T08:26:52.062925Z","iopub.status.idle":"2024-11-12T08:26:56.091255Z","shell.execute_reply":"2024-11-12T08:26:56.090184Z","shell.execute_reply.started":"2024-11-12T08:26:52.063753Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9acba804aba476896133d77d98438a3","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/761 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8579993b6fe497ca436fa7ed7c48e31","version_major":2,"version_minor":0},"text/plain":["(…)-00000-of-00001-52e35a24f615aa7b.parquet:   0%|          | 0.00/527k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c205ad99e8646eaa2429054f86b2797","version_major":2,"version_minor":0},"text/plain":["(…)-00000-of-00001-1d9ca8ce89c3de29.parquet:   0%|          | 0.00/107k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a12ab671e53d4ffeb8f8aeb8df4e581c","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/3138 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56e806d3976c4ab9b729fb99928745f9","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","\n","ds = load_dataset(\"cq01/mawps-asdiv-a_svamp\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.status.idle":"2024-11-12T08:31:47.742177Z","shell.execute_reply":"2024-11-12T08:31:47.741121Z","shell.execute_reply.started":"2024-11-12T08:26:56.094387Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Building wheels for collected packages: unsloth\n","  Building wheel for unsloth (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for unsloth: filename=unsloth-2024.11.5-py3-none-any.whl size=161005 sha256=5fd5c76804228bb858b6f651602020aaa24645ead497bcd032f8fdfa3b03829c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-z7zaq6ll/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n","Successfully built unsloth\n","Installing collected packages: unsloth, triton, sympy, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf-transfer, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, transformers, torch, xformers, bitsandbytes, trl, peft, unsloth-zoo\n","  Attempting uninstall: sympy\n","    Found existing installation: sympy 1.13.3\n","    Uninstalling sympy-1.13.3:\n","      Successfully uninstalled sympy-1.13.3\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.45.1\n","    Uninstalling transformers-4.45.1:\n","      Successfully uninstalled transformers-4.45.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","easyocr 1.7.2 requires torchvision>=0.5, which is not installed.\n","fastai 2.7.17 requires torchvision>=0.11, which is not installed.\n","timm 1.0.9 requires torchvision, which is not installed.\n","fastai 2.7.17 requires torch<2.5,>=1.10, but you have torch 2.5.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed bitsandbytes-0.44.1 hf-transfer-0.1.8 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 peft-0.13.2 shtab-1.7.1 sympy-1.13.1 torch-2.5.0 transformers-4.46.2 triton-3.1.0 trl-0.12.0 tyro-0.8.14 unsloth-2024.11.5 unsloth-zoo-2024.11.4 xformers-0.0.28.post2\n","Collecting torch==2.4.1\n","  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n","Collecting torchvision==0.19.1\n","  Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (3.15.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (4.12.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (1.13.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (3.1.4)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (2024.6.1)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (9.1.0.70)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1)\n","  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==3.0.0 (from torch==2.4.1)\n","  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.19.1) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.19.1) (10.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1) (12.4.127)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.4.1) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.4.1) (1.3.0)\n","Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m140.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m118.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, torch, torchvision\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.1.0\n","    Uninstalling triton-3.1.0:\n","      Successfully uninstalled triton-3.1.0\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.4.127\n","    Uninstalling nvidia-nvtx-cu12-12.4.127:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.21.5\n","    Uninstalling nvidia-nccl-cu12-2.21.5:\n","      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n","    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.5.147\n","    Uninstalling nvidia-curand-cu12-10.3.5.147:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n","    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n","    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n","    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n","    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n","      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n","    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.0\n","    Uninstalling torch-2.5.0:\n","      Successfully uninstalled torch-2.5.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xformers 0.0.28.post2 requires torch==2.5.0, but you have torch 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.1 torchvision-0.19.1 triton-3.0.0\n","Collecting xformers==0.0.28.post1\n","  Downloading xformers-0.0.28.post1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.28.post1) (1.26.4)\n","Requirement already satisfied: torch==2.4.1 in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.28.post1) (2.4.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (3.15.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (4.12.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (1.13.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (3.1.4)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (2024.6.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (12.1.105)\n","Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (3.0.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1->xformers==0.0.28.post1) (12.4.127)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.4.1->xformers==0.0.28.post1) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.4.1->xformers==0.0.28.post1) (1.3.0)\n","Downloading xformers-0.0.28.post1-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xformers\n","  Attempting uninstall: xformers\n","    Found existing installation: xformers 0.0.28.post2\n","    Uninstalling xformers-0.0.28.post2:\n","      Successfully uninstalled xformers-0.0.28.post2\n","Successfully installed xformers-0.0.28.post1\n"]}],"source":["!pip install --upgrade pip\n","\n","!pip uninstall unsloth -y\n","!pip uninstall torch torchvision -y\n","!pip uninstall xformers -y\n","\n","!pip install \"unsloth[cu124-torch250] @ git+https://github.com/unslothai/unsloth.git\"\n","!pip install torch==2.4.1 torchvision==0.19.1\n","!pip install --upgrade xformers==0.0.28.post1"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T08:31:47.743973Z","iopub.status.busy":"2024-11-12T08:31:47.743637Z","iopub.status.idle":"2024-11-12T08:31:49.619645Z","shell.execute_reply":"2024-11-12T08:31:49.618902Z","shell.execute_reply.started":"2024-11-12T08:31:47.743937Z"},"trusted":true},"outputs":[],"source":["import os\n","import torch\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T08:31:49.621972Z","iopub.status.busy":"2024-11-12T08:31:49.621663Z","iopub.status.idle":"2024-11-12T08:31:49.626731Z","shell.execute_reply":"2024-11-12T08:31:49.625840Z","shell.execute_reply.started":"2024-11-12T08:31:49.621939Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of 'train': 3138\n","Length of 'validation': 1000\n"]}],"source":["for key, value in ds.items():\n","    print(f\"Length of '{key}': {len(value)}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T08:31:49.628301Z","iopub.status.busy":"2024-11-12T08:31:49.627872Z","iopub.status.idle":"2024-11-12T08:31:50.500734Z","shell.execute_reply":"2024-11-12T08:31:50.499903Z","shell.execute_reply.started":"2024-11-12T08:31:49.628248Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4436148cb8134e82a6ef249a6fae7469","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/3138 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"249aae777e3c4b7ea7f5b8d766c68746","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["A construction company ordered 0.16666666666666666 ton of concrete , 0.16666666666666666 ton of bricks , and 0.5 ton of stone . How many tons of material did the company order in all ?\n"]}],"source":["def generate_full_question(example):\n","    question = example[\"Question\"]\n","    numbers = example[\"Numbers\"]\n","    for i, num in enumerate(numbers):\n","        placeholder = f\"number{i}\"\n","        # Check if the number is an integer\n","        if num.is_integer():\n","            num_str = str(int(num))\n","        else:\n","            num_str = str(num)\n","        question = question.replace(placeholder, num_str)\n","    example[\"Full Question\"] = question\n","    return example\n","\n","# Apply the transformation to the train and validation sets\n","ds = ds.map(generate_full_question)\n","\n","# Now you can access the transformed dataset with the new \"Full Question\" column\n","print(ds[\"train\"][23][\"Full Question\"])"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T08:31:50.502418Z","iopub.status.busy":"2024-11-12T08:31:50.502117Z","iopub.status.idle":"2024-11-12T08:31:50.509081Z","shell.execute_reply":"2024-11-12T08:31:50.508083Z","shell.execute_reply.started":"2024-11-12T08:31:50.502385Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Bryan took a look at his books as well . If Bryan has 56 books in each of his 9 bookshelves , how many books does he have in total ?\n","For the fifth grade play , the chairs have been put into 27 rows with 16 chairs in each row . How many chairs have been put out for the play ?\n","There are 41 short trees and 44 tall trees currently in the park . Park workers will plant 57 short trees today . How many short trees will the park have when the workers are finished ?\n"]}],"source":["print(ds[\"train\"][0][\"Full Question\"])\n","print(ds[\"train\"][1][\"Full Question\"])\n","print(ds[\"train\"][2][\"Full Question\"])"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T08:31:50.510531Z","iopub.status.busy":"2024-11-12T08:31:50.510249Z","iopub.status.idle":"2024-11-12T08:40:49.666595Z","shell.execute_reply":"2024-11-12T08:40:49.665727Z","shell.execute_reply.started":"2024-11-12T08:31:50.510500Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0614c36c50a943aab913782344c32f87","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55cf507b2052433fb61cecb0f66950ad","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa89672f767444fa84b9489543848451","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40fa2ca0e14e4566b395c2ad7a1b364a","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43c9be02a2394a76aabd04d83584d147","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"705b68c4dd34437e9f59d84b06cd5e0f","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/924 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"303414675d3647b4adfb4263793a47a8","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/39.1k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"584a521ff51a49d3a8b3ccda4a06b565","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3eaf9d4b6a5d45ce9541037c678895de","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d190909875654162922ea653051d49c6","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00004.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ba593bd8b8d48df8efa720ec553007e","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00004.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd95dba999bc43d883657c8dff13d175","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00004.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee5929df96294f66811f219fb1925658","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a98f974d599141d88db8a13917e3ad26","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","import torch\n","\n","local_model_path = \"unsloth/gemma-2-9b\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n","model = AutoModelForCausalLM.from_pretrained(\n","    local_model_path,\n","    device_map=\"auto\",  \n",")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T08:40:49.668378Z","iopub.status.busy":"2024-11-12T08:40:49.667799Z","iopub.status.idle":"2024-11-12T08:40:49.681357Z","shell.execute_reply":"2024-11-12T08:40:49.680320Z","shell.execute_reply.started":"2024-11-12T08:40:49.668340Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","\n","def extract_number_eval(text):\n","    \"\"\"Extract the last number from text using regex.\"\"\"\n","    numbers = re.findall(r\"[-+]?\\d*\\.?\\d+\", text)\n","    return float(numbers[-1]) if numbers else None\n","\n","def evaluate_accuracy(model, tokenizer, eval_dataset, num_samples=100):\n","    \"\"\"Evaluate model accuracy on a small subset of validation data.\"\"\"\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    \n","    # Sample random indices\n","    indices = np.random.choice(len(eval_dataset), num_samples, replace=False)\n","    eval_subset = eval_dataset\n","    \n","    evaluation_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Solve the following math problem. Provide only the numerical answer in the format: \"the answer is [number]\" without any explanation.\n","\n","### Input:\n","{question}\n","\n","### Response:\n","\"\"\"\n","    \n","    results = []\n","    \n","    print(f\"\\nEvaluating accuracy on {num_samples} examples...\")\n","    for example in tqdm(eval_subset):\n","        try:\n","            # Prepare input\n","            prompt = evaluation_prompt.format(question=example[\"Full Question\"])\n","            inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n","            \n","            # Generate prediction\n","            with torch.no_grad():\n","                outputs = model.generate(\n","                    # **inputs,\n","                    input_ids=inputs[\"input_ids\"],\n","                    max_new_tokens=32,\n","                    use_cache=False,\n","                    do_sample=False,\n","                )\n","            \n","            # Decode output\n","            generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","            \n","            # Extract prediction and true answer\n","            predicted_number = extract_number_eval(generated_text)\n","            true_answer = float(example[\"Answer\"])\n","            \n","            # Check if correct\n","            is_correct = (predicted_number is not None and abs(predicted_number - true_answer) < 1e-6)\n","            correct += int(is_correct)\n","            total += 1\n","            \n","            # Store result\n","            results.append({\n","                \"question\": example[\"Full Question\"],\n","                \"true_answer\": true_answer,\n","                \"predicted\": predicted_number,\n","                \"correct\": is_correct\n","            })\n","            \n","        except Exception as e:\n","            print(f\"Error processing example: {e}\")\n","            continue\n","    \n","    accuracy = correct / total if total > 0 else 0\n","    print(f\"Accuracy on {num_samples} samples: {accuracy:.2%}\")\n","    \n","    return accuracy, results"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T08:43:15.464148Z","iopub.status.busy":"2024-11-12T08:43:15.463725Z","iopub.status.idle":"2024-11-12T08:43:33.304904Z","shell.execute_reply":"2024-11-12T08:43:33.303912Z","shell.execute_reply.started":"2024-11-12T08:43:15.464107Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1100, in emit\n","    msg = self.format(record)\n","  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 943, in format\n","    return fmt.format(record)\n","  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 678, in format\n","    record.message = record.getMessage()\n","  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n","    msg = msg % self.args\n","TypeError: not all arguments converted during string formatting\n","Call stack:\n","  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n","    app.launch_new_instance()\n","  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n","    app.start()\n","  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n","    self.io_loop.start()\n","  File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n","    self._run_once()\n","  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n","    handle._run()\n","  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n","    await self.process_one()\n","  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n","    await dispatch(*args)\n","  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n","    await result\n","  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n","    await super().execute_request(stream, ident, parent)\n","  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n","    reply_content = await reply_content\n","  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n","    res = shell.run_cell(\n","  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n","    return super().run_cell(*args, **kwargs)\n","  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n","    result = self._run_cell(\n","  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n","    result = runner(coro)\n","  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n","    if await self.run_code(code, result, async_=asy):\n","  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"/tmp/ipykernel_30/3680568429.py\", line 30, in <module>\n","    outputs = model.generate(\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1971, in generate\n","    generation_config, model_kwargs = self._prepare_generation_config(generation_config, **kwargs)\n","  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1510, in _prepare_generation_config\n","    model_kwargs = generation_config.update(**kwargs)\n","  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py\", line 1279, in update\n","    self.validate()\n","  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py\", line 751, in validate\n","    logger.warning_once(\n","  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/logging.py\", line 328, in warning_once\n","    self.warning(*args, **kwargs)\n","Message: 'You have set `use_cache` to `False`, but cache_implementation is set to hybrid. cache_implementation will have no effect.'\n","Arguments: (<class 'UserWarning'>,)\n"]},{"name":"stdout","output_type":"stream","text":["Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Solve the following math problem. Provide only the numerical answer in the format: \"the answer is [number]\" without any explanation.\n","\n","### Input:\n","julia played tag with 18 kids on monday . she played tag with 10 kids on tuesday . how many more kids did she play with on monday than on tuesday ?\n","\n","### Response:\n","the answer is 8\n","\n","8.0\n"]}],"source":["#### Random test experiment\n","import re\n","\n","example = ds[\"validation\"][0]\n","evaluation_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Solve the following math problem. Provide only the numerical answer in the format: \"the answer is [number]\" without any explanation.\n","\n","### Input:\n","{question}\n","\n","### Response:\n","\"\"\"\n","\n","\n","prompt = evaluation_prompt.format(question=example[\"Full Question\"])\n","\n","# inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(model.device)\n","inputs = tokenizer(\n","        prompt, \n","        return_tensors=\"pt\", \n","        padding=True,\n","        truncation=True,\n","        max_length=512,  # Match with max_seq_length\n",").to(model.device)\n","\n","model.eval()\n","\n","outputs = model.generate(\n","    # **inputs,\n","    **inputs,\n","    eos_token_id=tokenizer.eos_token_id,  \n","    max_new_tokens=32,\n","    use_cache=False,\n","    do_sample=False,\n",")\n","\n","generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","print(generated_text)\n","predicted_number = extract_number_eval(generated_text)\n","print(predicted_number)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T14:11:33.053352Z","iopub.status.busy":"2024-11-12T14:11:33.052951Z","iopub.status.idle":"2024-11-12T14:11:33.063108Z","shell.execute_reply":"2024-11-12T14:11:33.062222Z","shell.execute_reply.started":"2024-11-12T14:11:33.053314Z"},"trusted":true},"outputs":[],"source":["print(\"\\nEvaluating model accuracy before fine-tuning...\")\n","initial_accuracy, initial_results = evaluate_accuracy(\n","    model, tokenizer, ds[\"validation\"], num_samples=len(ds[\"validation\"])\n",")\n","\n","# Save initial results\n","with open(\"without_finetuning_initial_evaluation.txt\", \"w\") as f:\n","    f.write(f\"Initial Accuracy: {initial_accuracy:.2%}\\n\")\n","    f.write(\"\\nDetailed Results:\\n\")\n","    for result in initial_results:  # Save first 10 examples\n","        f.write(f\"\\nQ: {result['question']}\")\n","        f.write(f\"\\nTrue: {result['true_answer']}, Predicted: {result['predicted']}\")\n","        f.write(f\"\\nCorrect: {result['correct']}\\n\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T14:09:03.869377Z","iopub.status.busy":"2024-11-12T14:09:03.868530Z","iopub.status.idle":"2024-11-12T14:09:03.874081Z","shell.execute_reply":"2024-11-12T14:09:03.873067Z","shell.execute_reply.started":"2024-11-12T14:09:03.869337Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.648\n"]}],"source":["print(initial_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
