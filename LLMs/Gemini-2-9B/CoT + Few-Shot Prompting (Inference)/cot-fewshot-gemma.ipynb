{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":169850,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":144506,"modelId":167065}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\nds = load_dataset(\"cq01/mawps-asdiv-a_svamp\")","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:54:17.615488Z","iopub.execute_input":"2024-11-18T11:54:17.615803Z","iopub.status.idle":"2024-11-18T11:54:23.567021Z","shell.execute_reply.started":"2024-11-18T11:54:17.615767Z","shell.execute_reply":"2024-11-18T11:54:23.566007Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/761 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02a56b69ca71457c935713415965167d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-52e35a24f615aa7b.parquet:   0%|          | 0.00/527k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5853a9cd95084369bc6616ab0a947c01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-1d9ca8ce89c3de29.parquet:   0%|          | 0.00/107k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35807fd4f6564013a82450fb9168c3f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3138 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25d91745fb6b433ea936af32b42d6a65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eea35411e07d447f9f9b686003ddd5bf"}},"metadata":{}}]},{"cell_type":"code","source":"!pip install --upgrade pip\n\n!pip uninstall unsloth -y\n!pip uninstall torch torchvision -y\n!pip uninstall xformers -y\n\n!pip install \"unsloth[cu124-torch250] @ git+https://github.com/unslothai/unsloth.git\"\n!pip install torch==2.4.1 torchvision==0.19.1\n!pip install --upgrade xformers==0.0.28.post1","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:54:23.568625Z","iopub.execute_input":"2024-11-18T11:54:23.569154Z","iopub.status.idle":"2024-11-18T12:00:09.705849Z","shell.execute_reply.started":"2024-11-18T11:54:23.569118Z","shell.execute_reply":"2024-11-18T12:00:09.704579Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (24.0)\nCollecting pip\n  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\nDownloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.0\n    Uninstalling pip-24.0:\n      Successfully uninstalled pip-24.0\nSuccessfully installed pip-24.3.1\n\u001b[33mWARNING: Skipping unsloth as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mFound existing installation: torch 2.4.0\nUninstalling torch-2.4.0:\n  Successfully uninstalled torch-2.4.0\nFound existing installation: torchvision 0.19.0\nUninstalling torchvision-0.19.0:\n  Successfully uninstalled torchvision-0.19.0\n\u001b[33mWARNING: Skipping xformers as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mCollecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-r5radcn0/unsloth_5cf6380b9718419588f362770ea75e53\n  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-r5radcn0/unsloth_5cf6380b9718419588f362770ea75e53\n  Resolved https://github.com/unslothai/unsloth.git to commit f26d4e739ed507de7a9088da53d10fd02f58d160\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting bitsandbytes>=0.43.3 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nCollecting torch (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\nCollecting xformers@ https://download.pytorch.org/whl/cu124/xformers-0.0.28.post2-cp310-cp310-manylinux_2_28_x86_64.whl (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading https://download.pytorch.org/whl/cu124/xformers-0.0.28.post2-cp310-cp310-manylinux_2_28_x86_64.whl (20.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting unsloth-zoo>=2024.11.1 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading unsloth_zoo-2024.11.5-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (21.3)\nCollecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading tyro-0.9.0-py3-none-any.whl.metadata (9.3 kB)\nCollecting transformers>=4.46.1 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\nRequirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.0.1)\nRequirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (5.9.3)\nRequirement already satisfied: wheel>=0.42.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\nRequirement already satisfied: accelerate>=0.34.1 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.34.2)\nCollecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading trl-0.12.1-py3-none-any.whl.metadata (10 kB)\nCollecting peft!=0.11.0,>=0.7.1 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: protobuf<4.0.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.25.1)\nCollecting hf-transfer (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.9.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.1.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.1.4)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.1.0 (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nCollecting sympy==1.13.1 (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.20.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (13.7.1)\nRequirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.16)\nCollecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nCollecting torch (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.8.30)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\nDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m134.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\nDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading trl-0.12.1-py3-none-any.whl (310 kB)\nDownloading unsloth_zoo-2024.11.5-py3-none-any.whl (31 kB)\nDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.9.0-py3-none-any.whl (4.5 kB)\nDownloading torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nBuilding wheels for collected packages: unsloth\n  Building wheel for unsloth (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for unsloth: filename=unsloth-2024.11.7-py3-none-any.whl size=163138 sha256=ce34fbab7a6e8021878b7ef21d5357ac51c0310aa850f526551a62d4b5d23078\n  Stored in directory: /tmp/pip-ephem-wheel-cache-coaow8cg/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\nSuccessfully built unsloth\nInstalling collected packages: unsloth, triton, sympy, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf-transfer, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, transformers, torch, xformers, bitsandbytes, trl, peft, unsloth-zoo\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.3\n    Uninstalling sympy-1.13.3:\n      Successfully uninstalled sympy-1.13.3\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.45.1\n    Uninstalling transformers-4.45.1:\n      Successfully uninstalled transformers-4.45.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\neasyocr 1.7.2 requires torchvision>=0.5, which is not installed.\nfastai 2.7.17 requires torchvision>=0.11, which is not installed.\ntimm 1.0.9 requires torchvision, which is not installed.\nfastai 2.7.17 requires torch<2.5,>=1.10, but you have torch 2.5.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.44.1 hf-transfer-0.1.8 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 peft-0.13.2 shtab-1.7.1 sympy-1.13.1 torch-2.5.0 transformers-4.46.2 triton-3.1.0 trl-0.12.1 tyro-0.9.0 unsloth-2024.11.7 unsloth-zoo-2024.11.5 xformers-0.0.28.post2\nCollecting torch==2.4.1\n  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nCollecting torchvision==0.19.1\n  Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (1.13.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (2024.6.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (9.1.0.70)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==3.0.0 (from torch==2.4.1)\n  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.19.1) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.19.1) (10.3.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1) (12.4.127)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.4.1) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.4.1) (1.3.0)\nDownloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m129.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m139.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\nDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, torch, torchvision\n  Attempting uninstall: triton\n    Found existing installation: triton 3.1.0\n    Uninstalling triton-3.1.0:\n      Successfully uninstalled triton-3.1.0\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.5.147\n    Uninstalling nvidia-curand-cu12-10.3.5.147:\n      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.0\n    Uninstalling torch-2.5.0:\n      Successfully uninstalled torch-2.5.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nxformers 0.0.28.post2 requires torch==2.5.0, but you have torch 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.1 torchvision-0.19.1 triton-3.0.0\nCollecting xformers==0.0.28.post1\n  Downloading xformers-0.0.28.post1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.28.post1) (1.26.4)\nRequirement already satisfied: torch==2.4.1 in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.28.post1) (2.4.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (1.13.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->xformers==0.0.28.post1) (3.0.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1->xformers==0.0.28.post1) (12.4.127)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.4.1->xformers==0.0.28.post1) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.4.1->xformers==0.0.28.post1) (1.3.0)\nDownloading xformers-0.0.28.post1-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: xformers\n  Attempting uninstall: xformers\n    Found existing installation: xformers 0.0.28.post2\n    Uninstalling xformers-0.0.28.post2:\n      Successfully uninstalled xformers-0.0.28.post2\nSuccessfully installed xformers-0.0.28.post1\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-11-18T12:00:09.707495Z","iopub.execute_input":"2024-11-18T12:00:09.707836Z","iopub.status.idle":"2024-11-18T12:00:11.843060Z","shell.execute_reply.started":"2024-11-18T12:00:09.707801Z","shell.execute_reply":"2024-11-18T12:00:11.842216Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"for key, value in ds.items():\n    print(f\"Length of '{key}': {len(value)}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-18T12:00:11.845114Z","iopub.execute_input":"2024-11-18T12:00:11.845422Z","iopub.status.idle":"2024-11-18T12:00:11.850382Z","shell.execute_reply.started":"2024-11-18T12:00:11.845388Z","shell.execute_reply":"2024-11-18T12:00:11.849513Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Length of 'train': 3138\nLength of 'validation': 1000\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\n# Check if a GPU is available\nprint(torch.cuda.is_available())","metadata":{"execution":{"iopub.status.busy":"2024-11-18T12:00:11.851507Z","iopub.execute_input":"2024-11-18T12:00:11.851805Z","iopub.status.idle":"2024-11-18T12:00:11.938744Z","shell.execute_reply.started":"2024-11-18T12:00:11.851773Z","shell.execute_reply":"2024-11-18T12:00:11.937609Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-11-18T12:00:11.939928Z","iopub.execute_input":"2024-11-18T12:00:11.940392Z","iopub.status.idle":"2024-11-18T12:00:12.066461Z","shell.execute_reply.started":"2024-11-18T12:00:11.940358Z","shell.execute_reply":"2024-11-18T12:00:12.065373Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def generate_full_question(example):\n    question = example[\"Question\"]\n    numbers = example[\"Numbers\"]\n    for i, num in enumerate(numbers):\n        placeholder = f\"number{i}\"\n        # Check if the number is an integer\n        if num.is_integer():\n            num_str = str(int(num))\n        else:\n            num_str = str(num)\n        question = question.replace(placeholder, num_str)\n    example[\"Full Question\"] = question\n    return example\n\n# Apply the transformation to the train and validation sets\nds = ds.map(generate_full_question)\n\n# Now you can access the transformed dataset with the new \"Full Question\" column\nprint(ds[\"train\"][23][\"Full Question\"])","metadata":{"execution":{"iopub.status.busy":"2024-11-18T12:00:12.067754Z","iopub.execute_input":"2024-11-18T12:00:12.068310Z","iopub.status.idle":"2024-11-18T12:00:12.897226Z","shell.execute_reply.started":"2024-11-18T12:00:12.068262Z","shell.execute_reply":"2024-11-18T12:00:12.896296Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3138 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d99282ddfe704f0c8f31554937bf1cbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a11cb4656b414d7bb90d3c8a8a3eef10"}},"metadata":{}},{"name":"stdout","text":"A construction company ordered 0.16666666666666666 ton of concrete , 0.16666666666666666 ton of bricks , and 0.5 ton of stone . How many tons of material did the company order in all ?\n","output_type":"stream"}]},{"cell_type":"code","source":"print(ds[\"train\"][0][\"Full Question\"])\nprint(ds[\"train\"][1][\"Full Question\"])\nprint(ds[\"train\"][2][\"Full Question\"])","metadata":{"execution":{"iopub.status.busy":"2024-11-18T12:00:12.898507Z","iopub.execute_input":"2024-11-18T12:00:12.898813Z","iopub.status.idle":"2024-11-18T12:00:12.905246Z","shell.execute_reply.started":"2024-11-18T12:00:12.898780Z","shell.execute_reply":"2024-11-18T12:00:12.904394Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Bryan took a look at his books as well . If Bryan has 56 books in each of his 9 bookshelves , how many books does he have in total ?\nFor the fifth grade play , the chairs have been put into 27 rows with 16 chairs in each row . How many chairs have been put out for the play ?\nThere are 41 short trees and 44 tall trees currently in the park . Park workers will plant 57 short trees today . How many short trees will the park have when the workers are finished ?\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\nlocal_model_path = \"unsloth/gemma-2-9b\"\n# local_model_path = \"/kaggle/input/gemma-2-9b/other/default/1/models/mathGemma-2-9b\"\n\ntokenizer = AutoTokenizer.from_pretrained(local_model_path)\nmodel = AutoModelForCausalLM.from_pretrained(\n    local_model_path,\n    device_map=\"auto\",  \n)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T12:00:12.906486Z","iopub.execute_input":"2024-11-18T12:00:12.906758Z","iopub.status.idle":"2024-11-18T12:09:31.821453Z","shell.execute_reply.started":"2024-11-18T12:00:12.906729Z","shell.execute_reply":"2024-11-18T12:09:31.820571Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a2fd43b98054d3a9fc37ed34d22d695"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/46.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b5a67037323442cb3b215270cb81330"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10f528a3d1574de69f354ab433fd2d31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"539cee052662415b8d7fb681c3081c9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"441cf440eb82448dbf915c83de16147c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/924 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"593ea78d76cc4567847267019fbc6e39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/39.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2f62bcdc5d548d8a1bd631031581322"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43c6b73cef454f23af73b16fbf0767af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e0585ee17ab4ac6b4f0f8548b43ced7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d586695c324144dda86831ed87a0b34d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af7aad67bb6046848c8eedf5fa8c8ab7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1d47fe1f520472d981ea781035bb1b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d74683c362654cbcbc5bd6fba12b8b32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b64e76bd64824a0b81c513b0ce9f241e"}},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef extract_number_eval(text):\n    # Extract the text after 'the answer is'\n    # match = re.search(r'the answer is\\s*(.*)', text, re.IGNORECASE)\n    match = re.search(r'### Response:\\s*the answer is\\s*(.*)', text, re.IGNORECASE | re.DOTALL)\n    if match:\n        number_text = match.group(1).strip()\n        # print('Number text is:', number_text)\n        number_text = re.sub(r'[^0-9\\.\\-\\+eE]', '', number_text)\n        # print('After removing non-digit characters, number_text is:', number_text)\n        if number_text.count('.') > 1:\n            parts = number_text.split('.', 1)\n            number_text = parts[0] + '.' + parts[1].replace('.', '')\n        try:\n            number = float(number_text)\n            return number\n        except ValueError:\n            numbers = re.findall(r\"[-+]?\\d*\\.?\\d+\", text)\n            return float(numbers[-1]) if numbers else None\n    else:\n        numbers = re.findall(r\"[-+]?\\d*\\.?\\d+\", text)\n        return float(numbers[-1]) if numbers else None\n    \n    \ndef extract_number_eval2(text):\n    matches = re.findall(r'the answer is (\\d+\\.?\\d*)', text)\n    if matches:\n        last_answer = float(matches[-1])  # Get the last match\n    else:\n        last_answer = extract_number_eval(text)\n        \n    return last_answer\n\ndef create_few_shot_examples(num_shots=3):\n    \"\"\"Create few-shot examples with CoT reasoning.\"\"\"\n    examples = [\n        {\n            \"question\": \"every day swayam spends 4 hours on learning english and 9 hours on learning chinese. how many more hours does he spend on learning chinese than he does on learning english?\",\n            \"reasoning\": \"\"\"Let's think step by step:\n1. Hours spent on Chinese = 9 hours\n2. Hours spent on English = 4 hours\n3. Hours spent more on Chinese than on English = Hours on Chinese - Hours on English = 9 - 4\nTherefore, the answer is 5\"\"\"\n        },\n        {\n            \"question\": \"A store offers a 20% discount on a $80 shirt. What is the final price?\",\n            \"reasoning\": \"\"\"Let's think step by step:\n1. Calculate the discount amount: $80 × 20% = $80 × 0.2 = $16\n2. Subtract discount from original price: $80 - $16 = $64\nTherefore, the answer is 64\"\"\"\n        },\n        {\n            \"question\": \"A recipe needs 2.5 cups of flour for 4 servings. How many cups are needed for 6 servings?\",\n            \"reasoning\": \"\"\"Let's think step by step:\n1. Find flour per serving: 2.5 ÷ 4 = 0.625 cups\n2. Multiply by new servings: 0.625 × 6\nTherefore, the answer is 3.75\"\"\"\n        }\n    ]\n    return examples[:num_shots] if num_shots > 0 else []\n    \n\ndef evaluate_accuracy(model, tokenizer, eval_dataset, num_samples=100, \n                      results_file=\"gemini_evaluation_results.txt\",\n                      responses_file=\"gemini_detailed_responses.txt\"):\n    \"\"\"Evaluate model accuracy on a small subset of validation data.\"\"\"\n    model.eval()\n    correct = 0\n    total = 0\n\n    eval_subset = eval_dataset\n\n    initial_results = []\n\n    evaluation_prompt =  \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nYou have to solve a math problem. Provide a brief, concise step-by-step solution and then provide the final numerical answer in the format: \"Therefore, the answer is [number]\"\n\nHere are some examples:\n\nExample-1: \n### Input:\nevery day swayam spends 4 hours on learning english and 9 hours on learning chinese. how many more hours does he spend on learning chinese than he does on learning english?\n\n### Response:\nLet's think step by step:\n1. Hours spent on Chinese = 9 hours\n2. Hours spent on English = 4 hours\n3. Hours spent more on Chinese than on English = Hours on Chinese - Hours on English = 9 - 4\nTherefore, the answer is 5\n\n\nExample-2:\n### Input:\na store offers a 20% discount on a $80 shirt. what is the final price?\n\n### Response:\nLet's think step by step:\n1. Calculate the discount amount: $80 × 20% = $80 × 0.2 = $16\n2. Subtract discount from original price: $80 - $16 = $64\nTherefore, the answer is 64\n\n\nNow solve the following math problem after thinking about the problem step by step:\n\n### Input:\n{question}\n\n### Response:\nLet's think step by step:\"\"\"\n\n    # Open the results file for writing\n    with open(results_file, \"w\") as file, open(responses_file, \"w\") as resp_file:\n        file.write(\"Evaluation Results:\\n\\n\")\n\n        print(f\"\\nEvaluating accuracy on {num_samples} examples...\")\n        progress_bar = tqdm(eval_subset, total=num_samples)\n        for example in progress_bar:\n            try:\n                # Prepare input\n                prompt = evaluation_prompt.format(question=example[\"Full Question\"])\n                inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n\n                # Generate prediction\n                with torch.no_grad():\n                    outputs = model.generate(\n                        input_ids=inputs[\"input_ids\"],\n                        max_new_tokens=512,\n                        use_cache=False,\n                        do_sample=False,\n                    )\n\n                # Decode output\n                generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n                # Extract prediction and true answer\n                predicted_number = extract_number_eval2(generated_text)\n                true_answer = float(example[\"Answer\"])\n\n                # Check if correct\n                is_correct = (predicted_number is not None and abs(predicted_number - true_answer) < 1e-6)\n                correct += int(is_correct)\n                total += 1\n\n                # Store result\n                result = {\n                    \"question\": example[\"Full Question\"],\n                    \"true_answer\": true_answer,\n                    \"predicted\": predicted_number,\n                    \"correct\": is_correct\n                }\n                \n                initial_results.append(result)\n                \n                results_line = (f\"Question: {result['question']}\\n\"\n                                f\"True Answer: {result['true_answer']}\\n\"\n                                f\"Predicted: {result['predicted']}\\n\"\n                                f\"Correct: {result['correct']}\\n\\n\")\n\n                # Write result to file\n                file.write(results_line)\n            \n                # Write detailed response\n                detailed_response = (f\"Question: {result['question']}\\n\"\n                                     f\"Complete Response:\\n{generated_text}\\n\"\n                                     f\"True Answer: {result['true_answer']}\\n\"\n                                     f\"Predicted: {result['predicted']}\\n\"\n                                     f\"Correct: {result['correct']}\\n\"\n                                     f\"{'-'*50}\\n\\n\")\n                resp_file.write(detailed_response)\n                \n                progress_bar.set_postfix(accuracy=f\"{(correct / total) * 100:.2f}%\")\n\n            except Exception as e:\n                error_message = f\"Error processing example: {e}\\n\"\n                print(error_message)\n                file.write(error_message)\n                continue\n\n        accuracy = correct / total if total > 0 else 0\n        accuracy_message = f\"\\nAccuracy on {num_samples} samples: {accuracy:.2%}\\n\"\n        print(accuracy_message)\n        file.write(accuracy_message)\n\n    return accuracy, initial_results","metadata":{"execution":{"iopub.status.busy":"2024-11-18T12:09:31.825222Z","iopub.execute_input":"2024-11-18T12:09:31.825903Z","iopub.status.idle":"2024-11-18T12:09:31.852307Z","shell.execute_reply.started":"2024-11-18T12:09:31.825868Z","shell.execute_reply":"2024-11-18T12:09:31.851474Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\nimport gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-11-18T12:09:31.853696Z","iopub.execute_input":"2024-11-18T12:09:31.854289Z","iopub.status.idle":"2024-11-18T12:09:32.159587Z","shell.execute_reply.started":"2024-11-18T12:09:31.854246Z","shell.execute_reply":"2024-11-18T12:09:32.158598Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"21"},"metadata":{}}]},{"cell_type":"code","source":"#### Random test experiment\nimport re\nimport time\n\nexample = ds[\"validation\"][51]\n\nevaluation_prompt =  \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nYou have to solve a math problem. Provide a brief, concise step-by-step solution and then provide the final numerical answer in the format: \"Therefore, the answer is [number]\"\n\nHere are some examples:\n\nExample-1: \n### Input:\nevery day swayam spends 4 hours on learning english and 9 hours on learning chinese. how many more hours does he spend on learning chinese than he does on learning english?\n\n### Response:\nLet's think step by step:\n1. Hours spent on Chinese = 9 hours\n2. Hours spent on English = 4 hours\n3. Hours spent more on Chinese than on English = Hours on Chinese - Hours on English = 9 - 4\nTherefore, the answer is 5\n\n\nExample-2:\n### Input:\na store offers a 20% discount on a $80 shirt. what is the final price?\n\n### Response:\nLet's think step by step:\n1. Calculate the discount amount: $80 × 20% = $80 × 0.2 = $16\n2. Subtract discount from original price: $80 - $16 = $64\nTherefore, the answer is 64\n\n\nNow solve the following math problem after thinking about the problem step by step:\n\n### Input:\n{question}\n\n### Response:\nLet's think step by step:\"\"\"\n\nstime = time.time()\n\nprompt = evaluation_prompt.format(question=example[\"Full Question\"])\n# print(prompt)\n# print(\"*****************\\n\\n\\n\")\n\n# inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(model.device)\ninputs = tokenizer(\n        prompt, \n        return_tensors=\"pt\", \n        padding=True,\n        truncation=True,\n        max_length=512,  # Match with max_seq_length\n).to(model.device)\n\nmodel.eval()\n\nwith torch.no_grad():\n    outputs = model.generate(\n        **inputs,\n        eos_token_id=tokenizer.eos_token_id,  \n        max_new_tokens=200,\n        use_cache=False,\n        do_sample=False,\n    )\n\ngenerated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(generated_text)\nprint('\\n\\n**********************\\n\\n')\npredicted_number = extract_number_eval(generated_text)\nprint(predicted_number)\n\netime = time.time()\nprint(etime - stime)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T12:09:32.160836Z","iopub.execute_input":"2024-11-18T12:09:32.161171Z","iopub.status.idle":"2024-11-18T12:12:01.924066Z","shell.execute_reply.started":"2024-11-18T12:09:32.161137Z","shell.execute_reply":"2024-11-18T12:12:01.923123Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1100, in emit\n    msg = self.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 943, in format\n    return fmt.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 678, in format\n    record.message = record.getMessage()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n    msg = msg % self.args\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n    await self.process_one()\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n    await dispatch(*args)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n    await result\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n    reply_content = await reply_content\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n    res = shell.run_cell(\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n    result = self._run_cell(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n    result = runner(coro)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_30/4178852279.py\", line 63, in <module>\n    outputs = model.generate(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1971, in generate\n    generation_config, model_kwargs = self._prepare_generation_config(generation_config, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1510, in _prepare_generation_config\n    model_kwargs = generation_config.update(**kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py\", line 1279, in update\n    self.validate()\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py\", line 751, in validate\n    logger.warning_once(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/logging.py\", line 328, in warning_once\n    self.warning(*args, **kwargs)\nMessage: 'You have set `use_cache` to `False`, but cache_implementation is set to hybrid. cache_implementation will have no effect.'\nArguments: (<class 'UserWarning'>,)\n","output_type":"stream"},{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nYou have to solve a math problem. Provide a brief, concise step-by-step solution and then provide the final numerical answer in the format: \"Therefore, the answer is [number]\"\n\nHere are some examples:\n\nExample-1: \n### Input:\nevery day swayam spends 4 hours on learning english and 9 hours on learning chinese. how many more hours does he spend on learning chinese than he does on learning english?\n\n### Response:\nLet's think step by step:\n1. Hours spent on Chinese = 9 hours\n2. Hours spent on English = 4 hours\n3. Hours spent more on Chinese than on English = Hours on Chinese - Hours on English = 9 - 4\nTherefore, the answer is 5\n\n\nExample-2:\n### Input:\na store offers a 20% discount on a $80 shirt. what is the final price?\n\n### Response:\nLet's think step by step:\n1. Calculate the discount amount: $80 × 20% = $80 × 0.2 = $16\n2. Subtract discount from original price: $80 - $16 = $64\nTherefore, the answer is 64\n\n\nNow solve the following math problem after thinking about the problem step by step:\n\n### Input:\nevery day ryan spends 7 hours on learning english and some more hours on learning chinese . if he spends 2 hours more on learning english than on learning chinese how many hours does he spend on learning chinese ?\n\n### Response:\nLet's think step by step:\n1. Hours spent on English = 7 hours\n2. Hours spent on Chinese = Hours on English - 2 hours = 7 - 2\nTherefore, the answer is 5\n\n\n\n**********************\n\n\n5.0\n149.74222922325134\n","output_type":"stream"}]},{"cell_type":"code","source":"ds[\"validation\"] = ds[\"validation\"].select(list(range(50))) \nprint(len(ds[\"validation\"]))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T12:12:01.925275Z","iopub.execute_input":"2024-11-18T12:12:01.925598Z","iopub.status.idle":"2024-11-18T12:12:01.937158Z","shell.execute_reply.started":"2024-11-18T12:12:01.925565Z","shell.execute_reply":"2024-11-18T12:12:01.936198Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"50\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"\\nEvaluating model accuracy after fine-tuning...\")\ninitial_accuracy, initial_results = evaluate_accuracy(\n    model, tokenizer, ds[\"validation\"], num_samples=len(ds[\"validation\"])\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T12:17:33.159117Z","iopub.execute_input":"2024-11-18T12:17:33.160018Z","iopub.status.idle":"2024-11-18T15:31:43.289174Z","shell.execute_reply.started":"2024-11-18T12:17:33.159963Z","shell.execute_reply":"2024-11-18T15:31:43.288224Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\nEvaluating model accuracy after fine-tuning...\n\nEvaluating accuracy on 50 examples...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [3:14:10<00:00, 233.00s/it, accuracy=96.00%]   ","output_type":"stream"},{"name":"stdout","text":"\nAccuracy on 50 samples: 96.00%\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}