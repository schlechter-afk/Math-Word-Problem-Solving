{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9530204,"sourceType":"datasetVersion","datasetId":5803771}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nimport sys\nimport math\nimport logging\nimport pdb\nimport json\nimport random\nfrom time import time\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport collections\nimport argparse\nfrom glob import glob\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom tensorboardX import SummaryWriter\nfrom gensim import models\nfrom collections import OrderedDict\nfrom transformers import BertModel, BertTokenizer, RobertaModel, RobertaTokenizer, AdamW\nfrom sympy import Eq, solve\nfrom sympy.parsing.sympy_parser import parse_expr\nfrom collections import OrderedDict\n# from attrdict import AttrDict\nfrom tensorboardX import SummaryWriter\nimport unicodedata\n\nimport sympy as sp\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# from attrdict import AttrDict\nimport unicodedata\ntry:\n\timport cPickle as pickle\nexcept ImportError:\n\timport pickle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:31:08.864595Z","iopub.execute_input":"2024-11-13T06:31:08.865067Z","iopub.status.idle":"2024-11-13T06:31:08.878139Z","shell.execute_reply.started":"2024-11-13T06:31:08.865021Z","shell.execute_reply":"2024-11-13T06:31:08.877114Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Components","metadata":{}},{"cell_type":"code","source":"##################################################\n# Attention.py #\n##################################################\n\n\n# Luong attention layer\nclass Attn(nn.Module):\n\tdef __init__(self, method, hidden_size):\n\t\tsuper(Attn, self).__init__()\n\t\tself.method = method\n\t\tif self.method not in ['dot', 'general', 'concat']:\n\t\t\traise ValueError(self.method, \"is not an appropriate attention method.\")\n\t\tself.hidden_size = hidden_size\n\t\tif self.method == 'general':\n\t\t\tself.attn = nn.Linear(self.hidden_size, hidden_size)\n\t\telif self.method == 'concat':\n\t\t\tself.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n\t\t\tself.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n\n\tdef dot_score(self, hidden, encoder_outputs):\n\t\treturn torch.sum(hidden * encoder_outputs, dim=2)\n\n\tdef general_score(self, hidden, encoder_outputs):\n\t\t# hidden: Tensor [1 x BS x hidden_size]\n\t\t# encoder_outputs: Tensor [seq_len x BS x hidden_size]\n\t\tenergy = self.attn(encoder_outputs)\n\t\treturn torch.sum(hidden * energy, dim=2)\n\n\tdef concat_score(self, hidden, encoder_outputs):\n\t\tenergy = self.attn(torch.cat((hidden.expand(encoder_outputs.size(0), -1, -1), encoder_outputs), 2)).tanh()\n\t\treturn torch.sum(self.v * energy, dim=2)\n\n\tdef forward(self, hidden, encoder_outputs):\n\t\t# Calculate the attention weights (energies) based on the given method\n\t\tif self.method == 'general':\n\t\t\tattn_energies = self.general_score(hidden, encoder_outputs)\n\t\telif self.method == 'concat':\n\t\t\tattn_energies = self.concat_score(hidden, encoder_outputs)\n\t\telif self.method == 'dot':\n\t\t\tattn_energies = self.dot_score(hidden, encoder_outputs)\n\n\t\t# Transpose max_length and batch_size dimensions\n\t\tattn_energies = attn_energies.t()\n\n\t\t# Return the softmax normalized probability scores (with added dimension)\n\t\treturn F.softmax(attn_energies, dim=1).unsqueeze(1)\n\nclass LuongAttnDecoderRNN(nn.Module):\n\tdef __init__(self, attn_model, embedding, cell_type, hidden_size, output_size, nlayers=1, dropout=0.1):\n\t\tsuper(LuongAttnDecoderRNN, self).__init__()\n\n\t\t# Keep for reference\n\t\tself.attn_model \t= attn_model\n\t\tself.hidden_size \t= hidden_size\n\t\tself.output_size \t= output_size\n\t\tself.nlayers \t\t= nlayers\n\t\tself.dropout \t\t= dropout\n\t\tself.cell_type \t\t= cell_type\n\n\t\t# Define layers\n\t\tself.embedding = embedding\n\t\tself.embedding_size  = self.embedding.embedding_dim\n\t\tself.embedding_dropout = nn.Dropout(self.dropout)\n\t\tif self.cell_type == 'gru':\n\t\t\tself.rnn = nn.GRU(self.embedding_size, self.hidden_size, self.nlayers, dropout=(0 if self.nlayers == 1 else self.dropout))\n\t\telse:\n\t\t\tself.rnn = nn.LSTM(self.embedding_size, self.hidden_size, self.nlayers, dropout=(0 if self.nlayers == 1 else self.dropout))\n\t\tself.concat = nn.Linear(self.hidden_size * 2, self.hidden_size)\n\t\tself.out = nn.Linear(self.hidden_size, self.output_size)\n\n\t\tself.attn = Attn(self.attn_model, self.hidden_size)\n\n\tdef forward(self, input_step, last_hidden, encoder_outputs):\n\t\t# Note: we run this one step (word) at a time\n\t\t# Get embedding of current input word\n\t\tembedded = self.embedding(input_step)\n\t\tembedded = self.embedding_dropout(embedded)\n\n\t\ttry:\n\t\t\tembedded = embedded.view(1, input_step.size(0), self.embedding_size)\n\t\texcept:\n\t\t\tembedded = embedded.view(1, 1, self.embedding_size)\n\n\t\trnn_output, hidden = self.rnn(embedded, last_hidden)\n\t\t# Calculate attention weights from the current GRU output\n\t\tattn_weights = self.attn(rnn_output, encoder_outputs)\n\t\t# attn_weights: Tensor [BS x 1 x seq_len]\n\t\t# Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n\t\tcontext = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n\t\t# Concatenate weighted context vector and GRU output using Luong eq. 5\n\t\trnn_output = rnn_output.squeeze(0)\n\t\tcontext = context.squeeze(1)\n\t\tconcat_input = torch.cat((rnn_output, context), 1)\n\t\tconcat_output = F.relu(self.concat(concat_input))\n\t\trepresentation = concat_output\n\t\t# Predict next word using Luong eq. 6\n\t\toutput = self.out(concat_output)\n\t\toutput = F.log_softmax(output, dim=1)\n\t\t# Return output and final hidden state\n\t\treturn output, hidden, attn_weights, representation\n\n\n##################################################\n# Contextual Embedding.py #\n##################################################\n\nclass BertEncoder(nn.Module):\n\tdef __init__(self, bert_model = 'bert-base-uncased',device = 'cuda:0 ', freeze_bert = False):\n\t\tsuper(BertEncoder, self).__init__()\n\t\tself.bert_layer = BertModel.from_pretrained(bert_model)\n\t\tself.bert_tokenizer = BertTokenizer.from_pretrained(bert_model)\n\t\tself.device = device\n\t\t\n\t\tif freeze_bert:\n\t\t\tfor p in self.bert_layer.parameters():\n\t\t\t\tp.requires_grad = False\n\t\t\n\tdef bertify_input(self, sentences):\n\t\t'''\n\t\tPreprocess the input sentences using bert tokenizer and converts them to a torch tensor containing token ids\n\n\t\t'''\n\t\t#Tokenize the input sentences for feeding into BERT\n\t\tall_tokens  = [['[CLS]'] + self.bert_tokenizer.tokenize(sentence) + ['[SEP]'] for sentence in sentences]\n\t\t\n\t\t#Pad all the sentences to a maximum length\n\t\tinput_lengths = [len(tokens) for tokens in all_tokens]\n\t\tmax_length    = max(input_lengths)\n\t\tpadded_tokens = [tokens + ['[PAD]' for _ in range(max_length - len(tokens))] for tokens in all_tokens]\n\n\t\t#Convert tokens to token ids\n\t\ttoken_ids = torch.tensor([self.bert_tokenizer.convert_tokens_to_ids(tokens) for tokens in padded_tokens]).to(self.device)\n\n\t\t#Obtain attention masks\n\t\tpad_token = self.bert_tokenizer.convert_tokens_to_ids('[PAD]')\n\t\tattn_masks = (token_ids != pad_token).long()\n\n\t\treturn token_ids, attn_masks, input_lengths\n\n\tdef forward(self, sentences):\n\t\t'''\n\t\tFeed the batch of sentences to a BERT encoder to obtain contextualized representations of each token\n\t\t'''\n\t\t#Preprocess sentences\n\t\ttoken_ids, attn_masks, input_lengths = self.bertify_input(sentences)\n\n\t\t#Feed through bert\n\t\t# cont_reps, _ = self.bert_layer(token_ids, attention_mask = attn_masks)\n\t\toutput = self.bert_layer(token_ids, attention_mask = attn_masks)\n\t\tcont_reps = output.last_hidden_state\n\n\t\treturn cont_reps, input_lengths\n\nclass RobertaEncoder(nn.Module):\n\tdef __init__(self, roberta_model = 'roberta-base', device = 'cuda:0 ', freeze_roberta = False):\n\t\tsuper(RobertaEncoder, self).__init__()\n\t\tself.roberta_layer = RobertaModel.from_pretrained(roberta_model)\n\t\tself.roberta_tokenizer = RobertaTokenizer.from_pretrained(roberta_model)\n\t\tself.device = device\n\t\t\n\t\tif freeze_roberta:\n\t\t\tfor p in self.roberta_layer.parameters():\n\t\t\t\tp.requires_grad = False\n\t\t\n\tdef robertify_input(self, sentences):\n\t\t'''\n\t\tPreprocess the input sentences using roberta tokenizer and converts them to a torch tensor containing token ids\n\n\t\t'''\n\t\t# Tokenize the input sentences for feeding into RoBERTa\n\t\tall_tokens  = [['<s>'] + self.roberta_tokenizer.tokenize(sentence) + ['</s>'] for sentence in sentences]\n\t\t\n\t\t# Pad all the sentences to a maximum length\n\t\tinput_lengths = [len(tokens) for tokens in all_tokens]\n\t\tmax_length    = max(input_lengths)\n\t\tpadded_tokens = [tokens + ['<pad>' for _ in range(max_length - len(tokens))] for tokens in all_tokens]\n\n\t\t# Convert tokens to token ids\n\t\ttoken_ids = torch.tensor([self.roberta_tokenizer.convert_tokens_to_ids(tokens) for tokens in padded_tokens]).to(self.device)\n\n\t\t# Obtain attention masks\n\t\tpad_token = self.roberta_tokenizer.convert_tokens_to_ids('<pad>')\n\t\tattn_masks = (token_ids != pad_token).long()\n\n\t\treturn token_ids, attn_masks, input_lengths\n\n\tdef forward(self, sentences):\n\t\t'''\n\t\tFeed the batch of sentences to a RoBERTa encoder to obtain contextualized representations of each token\n\t\t'''\n\t\t# Preprocess sentences\n\t\ttoken_ids, attn_masks, input_lengths = self.robertify_input(sentences)\n\n\t\t# Feed through RoBERTa\n\t\t# cont_reps, _ = self.roberta_layer(token_ids, attention_mask = attn_masks)\n\t\tcont_reps = self.roberta_layer.get_input_embeddings()(token_ids.transpose(0,1))\n\n\t\treturn cont_reps, input_lengths\n\n\n##################################################\n# decoder .py #\n##################################################","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:31:09.072886Z","iopub.execute_input":"2024-11-13T06:31:09.073669Z","iopub.status.idle":"2024-11-13T06:31:09.132675Z","shell.execute_reply.started":"2024-11-13T06:31:09.073615Z","shell.execute_reply":"2024-11-13T06:31:09.131289Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:31:09.072886Z","iopub.execute_input":"2024-11-13T06:31:09.073669Z","iopub.status.idle":"2024-11-13T06:31:09.132675Z","shell.execute_reply.started":"2024-11-13T06:31:09.073615Z","shell.execute_reply":"2024-11-13T06:31:09.131289Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:31:09.072886Z","iopub.execute_input":"2024-11-13T06:31:09.073669Z","iopub.status.idle":"2024-11-13T06:31:09.132675Z","shell.execute_reply.started":"2024-11-13T06:31:09.073615Z","shell.execute_reply":"2024-11-13T06:31:09.131289Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DecoderRNN(nn.Module):\n\t'''\n\tTo DO\n\tEncoder helps in building the sentence encoding module for a batched version\n\tof data that is sent in [T x B] having corresponding input lengths in [1 x B]\n\n\tArgs:\n\t\t\thidden_size: Hidden size of the RNN cell\n\t\t\tembedding: Embeddings matrix [vocab_size, embedding_dim]\n\t\t\tcell_type: Type of RNN cell to be used : LSTM, GRU\n\t\t\tnlayers: Number of layers of LSTM (default = 1)\n\t\t\tdropout: Dropout Rate (default = 0.1)\n\t\t\tbidirectional: Bidirectional model to be formed (default: False)\n\t'''\n\tdef __init__(self, embedding, cell_type, hidden_size, output_size, nlayers=1, dropout=0.2):\n\t\tsuper(DecoderRNN, self).__init__()\n\t\tself.hidden_size        = hidden_size\n\t\tself.cell_type          = cell_type\n\t\tself.embedding          = embedding\n\t\tself.embedding_size     = self.embedding.embedding_dim\n\t\tself.embedding_dropout = nn.Dropout(dropout)\n\t\tself.nlayers            = nlayers\n\t\tself.output_size        = output_size\n\n\t\tif self.cell_type == 'lstm':\n\t\t\tself.rnn = nn.LSTM(self.embedding_size, self.hidden_size, num_layers=self.nlayers, dropout=(0 if nlayers == 1 else dropout))\n\t\telse:\n\t\t\tself.rnn = nn.GRU(self.embedding_size, self.hidden_size, num_layers=self.nlayers, dropout=(0 if nlayers == 1 else dropout))\n\n\t\tself.out     = nn.Linear(self.hidden_size, self.output_size)\n\n\n\tdef forward(self, input_step, last_hidden):\n\t\t'''\n\t\tTo Do\n\t\t\tArgs:\n\t\t\t\tinput_seqs (tensor) : input tensor | size : [Seq_len X Batch_size]\n\t\t\t\tinput_lengths (list/tensor) : length of each input sentence | size : [Batch_size] \n\t\t\t\tdevice (gpu) : Used for sorting the sentences and putting it to device\n\n\t\t\tReturns:\n\t\t\t\toutput (tensor) : Last State representations of RNN [Seq_len X Batch_size X hidden_size]\n\t\t\t\thidden (tuple)\t: Hidden states and (cell states) of recurrent networks\n\t\t'''\n\t\toutput              = self.embedding(input_step)\n\t\toutput              = self.embedding_dropout(output)\n\t\toutput              = output.view(1, input_step.size(0), self.embedding_size)\n\t\toutput              = F.relu(output)\n\t\toutput, last_hidden = self.rnn(output, last_hidden)\n\t\toutput              = output.squeeze(0)\n\t\toutput              = self.out(output)\n\t\toutput              = F.log_softmax(output, dim=1)\n\n\t\treturn output, last_hidden\n\n\n##################################################\n# encoder.py #\n##################################################\n\nclass Encoder(nn.Module):\n\t'''\n\tEncoder helps in building the sentence encoding module for a batched version\n\tof data that is sent in [T x B] having corresponding input lengths in [1 x B]\n\n\tArgs:\n\t\t\thidden_size: Hidden size of the RNN cell\n\t\t\tembedding: Embeddings matrix [vocab_size, embedding_dim]\n\t\t\tcell_type: Type of RNN cell to be used : LSTM, GRU\n\t\t\tnlayers: Number of layers of LSTM (default = 1)\n\t\t\tdropout: Dropout Rate (default = 0.1)\n\t\t\tbidirectional: Bidirectional model to be formed (default: False)\n\t'''\n\n\tdef __init__(self, hidden_size=512,embedding_size = 768, cell_type='lstm', nlayers=1, dropout=0.1, bidirectional=True):\n\t\tsuper(Encoder, self).__init__()\n\t\tself.hidden_size = hidden_size\n\t\tself.nlayers = nlayers\n\t\tself.dropout = dropout\n\t\tself.cell_type = cell_type\n\t\tself.embedding_size = embedding_size\n\t\t# self.embedding_size = self.embedding.embedding_dim\n\t\tself.bidirectional = bidirectional\n\n\t\tif self.cell_type == 'lstm':\n\t\t\tself.rnn = nn.LSTM(self.embedding_size, self.hidden_size,\n\t\t\t\t\t\t\t   num_layers=self.nlayers,\n\t\t\t\t\t\t\t   dropout=(0 if self.nlayers == 1 else dropout),\n\t\t\t\t\t\t\t   bidirectional=bidirectional)\n\t\telif self.cell_type == 'gru':\n\t\t\tself.rnn = nn.GRU(self.embedding_size, self.hidden_size,\n\t\t\t\t\t\t\t  num_layers=self.nlayers,\n\t\t\t\t\t\t\t  dropout=(0 if self.nlayers == 1 else dropout),\n\t\t\t\t\t\t\t  bidirectional=bidirectional)\n\t\telse:\n\t\t\tself.rnn = nn.RNN(self.embedding_size, self.hidden_size,\n\t\t\t\t\t\t\t  num_layers=self.nlayers,\n\t\t\t\t\t\t\t  nonlinearity='tanh',\t\t\t\t\t\t\t# ['relu', 'tanh']\n\t\t\t\t\t\t\t  dropout=(0 if self.nlayers == 1 else dropout),\n\t\t\t\t\t\t\t  bidirectional=bidirectional)\n\n\t\tself.fc = nn.Linear(self.embedding_size, self.hidden_size)\n\n\tdef forward(self, sorted_seqs, sorted_len, orig_idx, device=None, hidden=None):\n\t\t'''\n\t\t\tArgs:\n\t\t\t\tinput_seqs (tensor) : input tensor | size : [Seq_len X Batch_size]\n\t\t\t\tinput_lengths (list/tensor) : length of each input sentence | size : [Batch_size] \n\t\t\t\tdevice (gpu) : Used for sorting the sentences and putting it to device\n\n\t\t\tReturns:\n\t\t\t\toutput (tensor) : Last State representations of RNN [Seq_len X Batch_size X hidden_size]\n\t\t\t\thidden (tuple)\t: Hidden states and (cell states) of recurrent networks\n\t\t'''\n\n\t\t# sorted_seqs, sorted_len, orig_idx = sort_by_len(input_seqs, input_lengths, device)\n\n\t\t#embedded = self.embedding(sorted_seqs)  ### NO MORE IDS\n\t\t# packed = torch.nn.utils.rnn.pack_padded_sequence(\n\t\t# \tsorted_seqs, sorted_len)\n\t\t# outputs, hidden = self.rnn(packed, hidden)\n\t\t# outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n\t\t# \toutputs)  # unpack (back to padded)\n\n\t\t# outputs = outputs.index_select(1, orig_idx)\n\n\t\t# if self.bidirectional:\n\t\t# \toutputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n\n\t\toutputs = self.fc(sorted_seqs)\n\t\toutputs = outputs.index_select(1, orig_idx)\n\t\thidden = torch.mean(outputs, 0).unsqueeze(0)\n\n\t\treturn outputs, hidden","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:31:09.072886Z","iopub.execute_input":"2024-11-13T06:31:09.073669Z","iopub.status.idle":"2024-11-13T06:31:09.132675Z","shell.execute_reply.started":"2024-11-13T06:31:09.073615Z","shell.execute_reply":"2024-11-13T06:31:09.131289Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## args.py","metadata":{}},{"cell_type":"code","source":"### Add Early Stopping ###\n\ndef build_parser():\n\t# Data loading parameters\n\tparser = argparse.ArgumentParser(description='Run Single sequence model')\n\n\t# Mode specifications\n\tparser.add_argument('-mode', type=str, default='train', choices=['train', 'test', 'conf'], help='Modes: train, test, conf')\n\tparser.add_argument('-debug', dest='debug', action='store_true', help='Operate in debug mode')\n\tparser.add_argument('-no-debug', dest='debug', action='store_false', help='Operate in normal mode')\n\tparser.set_defaults(debug=False)\n\n\t# Run Config\n\tparser.add_argument('-run_name', type=str, default='debug', help='run name for logs')\n\tparser.add_argument('-dataset', type=str, default='asdiv-a_fold0_final', help='Dataset')\n\tparser.add_argument('-display_freq', type=int, default= 10000, help='number of batches after which to display samples')\n\tparser.add_argument('-outputs', dest='outputs', action='store_true', help='Show full validation outputs')\n\tparser.add_argument('-no-outputs', dest='outputs', action='store_false', help='Do not show full validation outputs')\n\tparser.set_defaults(outputs=True)\n\tparser.add_argument('-results', dest='results', action='store_true', help='Store results')\n\tparser.add_argument('-no-results', dest='results', action='store_false', help='Do not store results')\n\tparser.set_defaults(results=True)\n\n\t# Meta Attributes\n\tparser.add_argument('-vocab_size', type=int, default=30000, help='Vocabulary size to consider')\n\tparser.add_argument('-histogram', dest='histogram', action='store_true', help='Operate in debug mode')\n\tparser.add_argument('-no-histogram', dest='histogram', action='store_false', help='Operate in normal mode')\n\tparser.set_defaults(histogram=True)\n\tparser.add_argument('-save_writer', dest='save_writer',action='store_true', help='To write tensorboard')\n\tparser.add_argument('-no-save_writer', dest='save_writer', action='store_false', help='Dont write tensorboard')\n\tparser.set_defaults(save_writer=False)\n\n\t# Device Configuration\n\tparser.add_argument('-gpu', type=int, default=1, help='Specify the gpu to use')\n\tparser.add_argument('-early_stopping', type=int, default=60, help='Early Stopping after n epoch')\n\tparser.add_argument('-seed', type=int, default=6174, help='Default seed to set')\n\tparser.add_argument('-logging', type=int, default=1, help='Set to 0 if you do not require logging')\n\tparser.add_argument('-ckpt', type=str, default='model', help='Checkpoint file name')\n\tparser.add_argument('-save_model', dest='save_model',action='store_true', help='To save the model')\n\tparser.add_argument('-no-save_model', dest='save_model', action='store_false', help='Dont save the model')\n\tparser.set_defaults(save_model=False)\n\t# parser.add_argument('-log_fmt', type=str, default='%(asctime)s | %(levelname)s | %(name)s | %(message)s', help='Specify format of the logger')\n\n\t# LSTM parameters\n\tparser.add_argument('-emb2_size', type=int, default=16, help='Embedding dimensions of inputs')\n\tparser.add_argument('-cell_type', type=str, default='lstm', help='RNN cell for encoder and decoder, default: lstm')\n\n\tparser.add_argument('-use_attn', dest='use_attn',action='store_true', help='To use attention mechanism?')\n\tparser.add_argument('-no-attn', dest='use_attn', action='store_false', help='Not to use attention mechanism?')\n\tparser.set_defaults(use_attn=True)\n\n\tparser.add_argument('-attn_type', type=str, default='general', help='Attention mechanism: (general, concat), default: general')\n\tparser.add_argument('-hidden_size', type=int, default=384, help='Number of hidden units in each layer')\n\tparser.add_argument('-depth', type=int, default=2, help='Number of layers in each encoder and decoder')\n\tparser.add_argument('-dropout', type=float, default=0.1, help= 'Dropout probability for input/output/state units (0.0: no dropout)')\n\tparser.add_argument('-max_length', type=int, default=100, help='Specify max decode steps: Max length string to output')\n\tparser.add_argument('-init_range', type=float, default=0.08, help='Initialization range for seq2seq model')\n\tparser.add_argument('-bidirectional', dest='bidirectional', action='store_true', help='Bidirectionality in LSTMs')\n\tparser.add_argument('-no-bidirectional', dest='bidirectional', action='store_false', help='Bidirectionality in LSTMs')\n\tparser.set_defaults(bidirectional=False)\n\tparser.add_argument('-lr', type=float, default=0.001, help='Learning rate')\n\t# parser.add_argument('-bert_lr', type=float, default=5e-5, help='Larning rate to train BERT embeddings')\n\tparser.add_argument('-warmup', type=float, default=0.1, help='Proportion of training to perform linear learning rate warmup for')\n\tparser.add_argument('-max_grad_norm', type=float, default=0.25, help='Clip gradients to this norm')\n\tparser.add_argument('-batch_size', type=int, default=4, help='Batch size')\n\tparser.add_argument('-epochs', type=int, default=60, help='Maximum # of training epochs')\n\tparser.add_argument('-opt', type=str, default='adam', choices=['adam', 'adadelta', 'sgd', 'asgd'], help='Optimizer for training')\n\tparser.add_argument('-separate_opt', dest='separate_opt', action='store_true', help='Separate Optimizers for Embedding and model - AdamW for emb and Adam for model')\n\tparser.add_argument('-no-separate_opt', dest='separate_opt', action='store_false', help='Common optimizer for Embedding and model')\n\tparser.set_defaults(separate_opt=False)\n\tparser.add_argument('-teacher_forcing_ratio', type=float, default=0.9, help='Teacher forcing ratio')\n\n\t# Embeddings\n\tparser.add_argument('-embedding', type=str, default='roberta', choices=['bert', 'roberta', 'word2vec', 'random'], help='Embeddings')\n\t# parser.add_argument('-use_word2vec', dest='use_word2vec', action='store_true', help='use word2vec')\n\t# parser.add_argument('-no-use_word2vec', dest='use_word2vec', action='store_false', help='Do not use word2vec')\n\t# parser.set_defaults(use_word2vec=False)\n\t# parser.add_argument('-word2vec_bin', type=str, default='/datadrive/satwik/global_data/glove.840B.300d.txt', help='Binary file of word2vec')\n\tparser.add_argument('-word2vec_bin', type=str, default='/datadrive/global_files/GoogleNews-vectors-negative300.bin', help='Binary file of word2vec')\n\t# parser.add_argument('-train_word2vec', dest='train_word2vec', action='store_true', help='train word2vec')\n\t# parser.add_argument('-no-train_word2vec', dest='train_word2vec', action='store_false', help='Do not train word2vec')\n\t# parser.set_defaults(train_word2vec=True)\n\tparser.add_argument('-emb1_size', type=int, default=768, help='Embedding dimensions of inputs')\n\tparser.add_argument('-emb_name', type=str, default='roberta-base', choices=['bert-base-uncased', 'roberta-base'], help='Which pre-trained model')\n\t# parser.add_argument('-bert_size', type=int, default = 768, help = 'Size of BERT\\'s last layer representations')\n\tparser.add_argument('-emb_lr', type=float, default=1e-5, help='Larning rate to train embeddings')\n\tparser.add_argument('-freeze_emb', dest='freeze_emb', action='store_true', help='Freeze embedding weights')\n\tparser.add_argument('-no-freeze_emb', dest='freeze_emb', action='store_false', help='Train embedding weights')\n\tparser.set_defaults(freeze_emb=False)\n\n\tparser.add_argument('-grade_disp', dest='grade_disp', action='store_true', help='Display grade information in validation outputs')\n\tparser.add_argument('-no-grade_disp', dest='grade_disp', action='store_false', help='Don\\'t display grade information')\n\tparser.set_defaults(grade_disp=False)\n\tparser.add_argument('-type_disp', dest='type_disp', action='store_true', help='Display Type information in validation outputs')\n\tparser.add_argument('-no-type_disp', dest='type_disp', action='store_false', help='Don\\'t display Type information')\n\tparser.set_defaults(type_disp=False)\n\tparser.add_argument('-nums_disp', dest='nums_disp', action='store_true', help='Display number of numbers information in validation outputs')\n\tparser.add_argument('-no-nums_disp', dest='nums_disp', action='store_false', help='Don\\'t display number of numbers information')\n\tparser.set_defaults(nums_disp=True)\n\tparser.add_argument('-challenge_disp', dest='challenge_disp', action='store_true', help='Display information in validation outputs')\n\tparser.add_argument('-no-challenge_disp', dest='challenge_disp', action='store_false', help='Don\\'t display information')\n\tparser.set_defaults(challenge_disp=False)\n\tparser.add_argument('-more_nums', dest='more_nums', action='store_true', help='More numbers in Voc2')\n\tparser.add_argument('-no-more_nums', dest='more_nums', action='store_false', help='Usual numbers in Voc2')\n\tparser.set_defaults(more_nums=False)\n\tparser.add_argument('-mawps_vocab', dest='mawps_vocab', action='store_true', help='Custom Numbers in Voc2')\n\tparser.add_argument('-no-mawps_vocab', dest='mawps_vocab', action='store_false', help='No Custom Numbers in Voc2')\n\tparser.set_defaults(mawps_vocab=False)\n\n\tparser.add_argument('-show_train_acc', dest='show_train_acc', action='store_true', help='Calculate the train accuracy')\n\tparser.add_argument('-no-show_train_acc', dest='show_train_acc', action='store_false', help='Don\\'t calculate the train accuracy')\n\tparser.set_defaults(show_train_acc=True)\n\n\tparser.add_argument('-full_cv', dest='full_cv', action='store_true', help='5-fold CV')\n\tparser.add_argument('-no-full_cv', dest='full_cv', action='store_false', help='No 5-fold CV')\n\tparser.set_defaults(full_cv=False)\n\n\t#Conf parameters\n\tparser.add_argument('-conf', type = str, default = 'posterior', choices = [\"posterior\", \"similarity\"], help = 'Confidence estimation criteria to use, [\"posterior\", \"similarity\"]')\n\tparser.add_argument('-sim_criteria', type = str, default = 'bleu', choices = ['bert_score', 'bleu_score'], help = 'Only applicable if similarity based criteria is selected for confidence.')\n\tparser.add_argument('-adv', action = 'store_true', help = 'If dealing with out of distribution examples')\n\t\n\treturn parser\n\ndef parse_arguments(arg_dict=None):\n    parser = build_parser()\n    if arg_dict:\n        # Override default values with provided dictionary values\n        args = parser.parse_args([])\n        for key, value in arg_dict.items():\n            setattr(args, key, value)\n        return args\n    else:\n        return parser.parse_args()  # If no dictionary is provided, use default command line arguments","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:31:09.163061Z","iopub.execute_input":"2024-11-13T06:31:09.163424Z","iopub.status.idle":"2024-11-13T06:31:09.201358Z","shell.execute_reply.started":"2024-11-13T06:31:09.163392Z","shell.execute_reply":"2024-11-13T06:31:09.200309Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## utils folder","metadata":{}},{"cell_type":"code","source":"##################################################\n# Bleu.py #\n##################################################\n\n# Copyright 2017 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n\"\"\"Python implementation of BLEU and smooth-BLEU.\nThis module provides a Python implementation of BLEU and smooth-BLEU.\nSmooth BLEU is computed following the method outlined in the paper:\nChin-Yew Lin, Franz Josef Och. ORANGE: a method for evaluating automatic\nevaluation metrics for machine translation. COLING 2004.\n\"\"\"\n\ndef _get_ngrams(segment, max_order):\n  \"\"\"Extracts all n-grams upto a given maximum order from an input segment.\n  Args:\n    segment: text segment from which n-grams will be extracted.\n    max_order: maximum length in tokens of the n-grams returned by this\n        methods.\n  Returns:\n    The Counter containing all n-grams upto max_order in segment\n    with a count of how many times each n-gram occurred.\n  \"\"\"\n  ngram_counts = collections.Counter()\n  for order in range(1, max_order + 1):\n    for i in range(0, len(segment) - order + 1):\n      ngram = tuple(segment[i:i+order])\n      ngram_counts[ngram] += 1\n  return ngram_counts\n\n\ndef compute_bleu(reference_corpus, translation_corpus, max_order=4,\n                 smooth=False):\n  \"\"\"Computes BLEU score of translated segments against one or more references.\n  Args:\n    reference_corpus: list of lists of references for each translation. Each\n        reference should be tokenized into a list of tokens.\n    translation_corpus: list of translations to score. Each translation\n        should be tokenized into a list of tokens.\n    max_order: Maximum n-gram order to use when computing BLEU score.\n    smooth: Whether or not to apply Lin et al. 2004 smoothing.\n  Returns:\n    3-Tuple with the BLEU score, n-gram precisions, geometric mean of n-gram\n    precisions and brevity penalty.\n  \"\"\"\n  matches_by_order = [0] * max_order\n  possible_matches_by_order = [0] * max_order\n  reference_length = 0\n  translation_length = 0\n  for (references, translation) in zip(reference_corpus,\n                                       translation_corpus):\n    reference_length += min(len(r) for r in references)\n    translation_length += len(translation)\n\n    merged_ref_ngram_counts = collections.Counter()\n    for reference in references:\n      merged_ref_ngram_counts |= _get_ngrams(reference, max_order)\n    translation_ngram_counts = _get_ngrams(translation, max_order)\n    overlap = translation_ngram_counts & merged_ref_ngram_counts\n    for ngram in overlap:\n      matches_by_order[len(ngram)-1] += overlap[ngram]\n    for order in range(1, max_order+1):\n      possible_matches = len(translation) - order + 1\n      if possible_matches > 0:\n        possible_matches_by_order[order-1] += possible_matches\n\n  precisions = [0] * max_order\n  for i in range(0, max_order):\n    if smooth:\n      precisions[i] = ((matches_by_order[i] + 1.) /\n                       (possible_matches_by_order[i] + 1.))\n    else:\n      if possible_matches_by_order[i] > 0:\n        precisions[i] = (float(matches_by_order[i]) /\n                         possible_matches_by_order[i])\n      else:\n        precisions[i] = 0.0\n\n  if min(precisions) > 0:\n    p_log_sum = sum((1. / max_order) * math.log(p) for p in precisions)\n    geo_mean = math.exp(p_log_sum)\n  else:\n    geo_mean = 0\n\n  ratio = float(translation_length) / reference_length\n\n  if ratio > 1.0:\n    bp = 1.\n  else:\n    if ratio > 1E-1:\n        bp = math.exp(1 - 1. / ratio)\n    else:\n        bp = 1E-2\n\n  bleu = geo_mean * bp\n\n  return (bleu, precisions, bp, ratio, translation_length, reference_length)\n\n\n##################################################\n# eq_preprocessing.py #\n##################################################\n\nOPS = ['+', '-', '*', '/']\n\nclass Node():\n    def __init__(self, val):\n        self.val    = val\n        self.left   = None\n        self.right  = None\n\n\ndef preorder(node, prefix = ''):\n    if node is None:\n        return prefix\n    val = node.val\n    prefix += val +' '\n    prefix = preorder(node.left, prefix)\n    prefix = preorder(node.right, prefix)\n    return prefix\n\ndef expr2tree(string):\n    tokens = string.split()\n    if len(tokens) == 1:\n        return Node(tokens[0])\n    i = 0\n    while i < len(tokens):\n        if tokens[i] in OPS:\n            break\n        i += 1\n\n    node = Node(tokens[i])\n    node.left  = expr2tree(' '.join(tokens[:i]))\n    node.right = expr2tree(' '.join(tokens[i+1:])) \n    return node\n\ndef infix2prefix(equation):\n    tree_root = expr2tree(equation)\n    prefix = preorder(tree_root, '')\n    return prefix\n\n# if __name__ == \"__main__\":\n#     parser = argparse.ArgumentParser()\n#     parser.add_argument('-eqn', required=True, type = str)\n#     args = parser.parse_args()\n\n#     print(infix2prefix(args.eqn))\n\n\n##################################################\n# evaluate.py #\n##################################################\n\n\ndef format_eq(eq):\n\tfin_eq = \"\"\n\tls = ['0','1','2','3','4','5','6','7','8','9','.']\n\ttemp_num = \"\"\n\tflag = 0\n\tfor i in eq:\n\t\tif flag > 0:\n\t\t\tfin_eq = fin_eq + i\n\t\t\tflag = flag-1\n\t\telif i == 'n':\n\t\t\tflag = 6\n\t\t\tif fin_eq == \"\":\n\t\t\t\tfin_eq = fin_eq + i\n\t\t\telse:\n\t\t\t\tfin_eq = fin_eq + ' ' + i\n\t\telif i in ls:\n\t\t\ttemp_num = temp_num + i\n\t\telif i == ' ':\n\t\t\tif temp_num == \"\":\n\t\t\t\tcontinue\n\t\t\telse:\n\t\t\t\tif fin_eq == \"\":\n\t\t\t\t\tfin_eq = fin_eq + temp_num\n\t\t\t\telse:\n\t\t\t\t\tfin_eq = fin_eq + ' ' + temp_num\n\t\t\ttemp_num = \"\"\n\t\telse:\n\t\t\tif fin_eq == \"\":\n\t\t\t\tif temp_num == \"\":\n\t\t\t\t\tfin_eq = fin_eq + i\n\t\t\t\telse:\n\t\t\t\t\tfin_eq = fin_eq + temp_num + ' ' + i\n\t\t\telse:\n\t\t\t\tif temp_num == \"\":\n\t\t\t\t\tfin_eq = fin_eq + ' ' + i\n\t\t\t\telse:\n\t\t\t\t\tfin_eq = fin_eq + ' ' + temp_num + ' ' + i\n\t\t\ttemp_num = \"\"\n\tif temp_num != \"\":\n\t\tfin_eq = fin_eq + ' ' + temp_num\n\treturn fin_eq\n\ndef prefix_to_infix(prefix):\n\toperators = ['+', '-', '*', '/']\n\tstack = []\n\telements = format_eq(prefix).split()\n\tfor i in range(len(elements)-1, -1, -1):\n\t\tif elements[i] in operators and len(stack)>1:\n\t\t\top1 = stack.pop(-1)\n\t\t\top2 = stack.pop(-1)\n\t\t\tfin_operand = '(' + ' ' + op1 + ' ' + elements[i] + ' ' + op2 + ' ' + ')'\n\t\t\tstack.append(fin_operand)\n\t\telse:\n\t\t\tstack.append(elements[i])\n\ttry:\n\t\treturn stack[0]\n\texcept:\n\t\treturn \"\"\n\ndef stack_to_string(stack):\n\top = \"\"\n\tfor i in stack:\n\t\tif op == \"\":\n\t\t\top = op + i\n\t\telse:\n\t\t\top = op + ' ' + i\n\treturn op\n\ndef back_align(eq, list_num):\n\telements = eq.split()\n\tfor i in range(len(elements)):\n\t\tif elements[i][0] == 'n':\n\t\t\tindex = int(elements[i][6])\n\t\t\ttry:\n\t\t\t\tnumber = str(list_num[index])\n\t\t\texcept:\n\t\t\t\treturn '-1000.112'\n\t\t\telements[i] = number\n\treturn stack_to_string(elements)    \n\ndef ans_evaluator(eq, list_num):\n\t#pdb.set_trace()\n\tinfix = prefix_to_infix(eq)\n\taligned = back_align(infix, list_num)\n\ttry:\n\t\tfinal_ans = parse_expr(aligned, evaluate = True)\n\texcept:\n\t\tfinal_ans = -1000.112\n\treturn final_ans\n\ndef cal_score(outputs, nums, ans):\n\tcorr = 0\n\ttot = 0\n\tdisp_corr = []\n\tfor i in range(len(outputs)):\n\t\top = stack_to_string(outputs[i])\n\t\tnum = nums[i].split()\n\t\tnum = [float(nu) for nu in num]\n\t\tanswer = ans[i].item()\n\n\t\tpred = ans_evaluator(op, num)\n\n\t\tif abs(pred - answer) <= 0.1:\n\t\t\tcorr+=1\n\t\t\ttot+=1\n\t\t\tdisp_corr.append(1)\n\t\telse:\n\t\t\ttot+=1\n\t\t\tdisp_corr.append(0)\n\n\treturn corr, tot, disp_corr\n\ndef get_infix_eq(outputs, nums):\n\teqs = []\n\tfor i in range(len(outputs)):\n\t\top = stack_to_string(outputs[i])\n\t\tnum = nums[i].split()\n\t\tnum = [float(nu) for nu in num]\n\n\t\tinfix = prefix_to_infix(op)\n\t\teqs.append(infix)\n\n\treturn eqs\n\n\n##################################################\n# helper.py #\n##################################################\ndef gpu_init_pytorch(gpu_num):\n\t'''\n\t\tInitialize GPU\n\t'''\n\ttorch.cuda.set_device(int(gpu_num))\n\tdevice = torch.device(\"cuda:{}\".format(\n\t\tgpu_num) if torch.cuda.is_available() else \"cpu\")\n\treturn device\n\ndef create_save_directories(path):\n\tif not os.path.exists(path):\n\t\tos.makedirs(path)\n\ndef save_checkpoint(state, epoch, logger, model_path, ckpt):\n\t'''\n\t\tSaves the model state along with epoch number. The name format is important for \n\t\tthe load functions. Don't mess with it.\n\n\t\tArgs:\n\t\t\tmodel state\n\t\t\tepoch number\n\t\t\tlogger variable\n\t\t\tdirectory to save models\n\t\t\tcheckpoint name\n\t'''\n\tckpt_path = os.path.join(model_path, '{}.pt'.format(ckpt))\n\tlogger.info('Saving Checkpoint at : {}'.format(ckpt_path))\n\ttorch.save(state, ckpt_path)\n\ndef get_latest_checkpoint(model_path, logger):\n\t'''\n\t\tLooks for the checkpoint with highest epoch number in the directory \"model_path\" \n\n\t\tArgs:\n\t\t\tmodel_path: including the run_name\n\t\t\tlogger variable: to log messages\n\t\tReturns:\n\t\t\tcheckpoint: path to the latest checkpoint \n\t'''\n\n\tckpts = glob('{}/*.pt'.format(model_path))\n\tckpts = sorted(ckpts)\n\n\tif len(ckpts) == 0:\n\t\tlogger.warning('No Checkpoints Found')\n\n\t\treturn None\n\telse:\n\t\t#pdb.set_trace()\n\t\t#latest_epoch = max([int(x.split('_')[-1].split('.')[0]) for x in ckpts])\n\t\t#ckpts = sorted(ckpts, key= lambda x: int(x.split('_')[-1].split('.')[0]) , reverse=True )\n\t\tckpt_path = ckpts[0]\n\t\t#logger.info('Checkpoint found with epoch number : {}'.format(latest_epoch))\n\t\tlogger.debug('Checkpoint found at : {}'.format(ckpt_path))\n\n\t\treturn ckpt_path\n\ndef load_checkpoint(config, model, mode, ckpt_path, logger, device):\n\tcheckpoint = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n\tmodel.load_state_dict(checkpoint['model_state_dict'])\n\tmodel.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n\tif config.separate_opt:\n\t\tmodel.emb_optimizer.load_state_dict(checkpoint['emb_optimizer_state_dict'])\n\tstart_epoch = checkpoint['epoch']\n\tmin_train_loss  =checkpoint['min_train_loss']\n\tmin_val_loss = checkpoint['min_val_loss']\n\tvoc1 = checkpoint['voc1']\n\tvoc2 = checkpoint['voc2']\n\tmax_train_acc = checkpoint['max_train_acc']\n\tmax_val_acc = checkpoint['max_val_acc']\n\tmax_val_bleu = checkpoint['max_val_bleu']\n\tbest_epoch = checkpoint['best_epoch']\n\n\tmodel.to(device)\n\n\tif mode == 'train':\n\t\tmodel.train()\n\telse:\n\t\tmodel.eval()\n\n\tlogger.info('Successfully Loaded Checkpoint from {}, with epoch number: {} for {}'.format(ckpt_path, start_epoch, mode))\n\n\treturn start_epoch, min_train_loss, min_val_loss, max_train_acc, max_val_acc, max_val_bleu, best_epoch, voc1, voc2\n\nclass Voc1:\n\tdef __init__(self):\n\t\tself.trimmed = False\n\t\tself.frequented = False\n\t\tself.w2id = {'<s>': 0, '</s>': 1, 'unk': 2}\n\t\tself.id2w = {0: '<s>', 1: '</s>', 2: 'unk'}\n\t\tself.w2c = {}\n\t\tself.nwords = 3\n\n\tdef add_word(self, word):\n\t\tif word not in self.w2id:\n\t\t\tself.w2id[word] = self.nwords\n\t\t\tself.id2w[self.nwords] = word\n\t\t\tself.w2c[word] = 1\n\t\t\tself.nwords += 1\n\t\telse:\n\t\t\tself.w2c[word] += 1\n\n\tdef add_sent(self, sent):\n\t\tfor word in sent.split():\n\t\t\tself.add_word(word)\n\n\tdef most_frequent(self, topk):\n\t\t# if self.frequented == True:\n\t\t# \treturn\n\t\t# self.frequented = True\n\n\t\tkeep_words = []\n\t\tcount = 3\n\t\tsort_by_value = sorted(\n\t\t\tself.w2c.items(), key=lambda kv: kv[1], reverse=True)\n\t\tfor word, freq in sort_by_value:\n\t\t\tkeep_words += [word]*freq\n\t\t\tcount += 1\n\t\t\tif count == topk:\n\t\t\t\tbreak\n\n\t\tself.w2id = {'<s>': 0, '</s>': 1, 'unk': 2}\n\t\tself.id2w = {0: '<s>', 1: '</s>', 2: 'unk'}\n\t\tself.w2c = {}\n\t\tself.nwords = 3\n\n\t\tfor word in keep_words:\n\t\t\tself.add_word(word)\n\n\tdef trim(self, mincount):\n\t\tif self.trimmed == True:\n\t\t\treturn\n\t\tself.trimmed = True\n\n\t\tkeep_words = []\n\t\tfor k, v in self.w2c.items():\n\t\t\tif v >= mincount:\n\t\t\t\tkeep_words += [k]*v\n\n\t\tself.w2id = {'<s>': 0, '</s>': 1, 'unk': 2}\n\t\tself.id2w = {0: '<s>', 1: '</s>', 2: 'unk'}\n\t\tself.w2c = {}\n\t\tself.nwords = 3\n\t\tfor word in keep_words:\n\t\t\tself.addWord(word)\n\n\tdef get_id(self, idx):\n\t\treturn self.w2id[idx]\n\n\tdef get_word(self, idx):\n\t\treturn self.id2w[idx]\n\n\tdef create_vocab_dict(self, args, train_dataloader):\n\t\tfor data in train_dataloader:\n\t\t\tfor sent in data['ques']:\n\t\t\t\tself.add_sent(sent)\n\n\t\tself.most_frequent(args.vocab_size)\n\t\tassert len(self.w2id) == self.nwords\n\t\tassert len(self.id2w) == self.nwords\n\n\tdef add_to_vocab_dict(self, args, dataloader):\n\t\tfor data in dataloader:\n\t\t\tfor sent in data['ques']:\n\t\t\t\tself.add_sent(sent)\n\n\t\tself.most_frequent(args.vocab_size)\n\t\tassert len(self.w2id) == self.nwords\n\t\tassert len(self.id2w) == self.nwords\n\nclass Voc2:\n\tdef __init__(self, config):\n\t\tself.frequented = False\n\t\tif config.more_nums:\n\t\t\tself.w2id = {'<s>': 0, '</s>': 1, '+': 2, '-': 3, '*': 4, '/': 5, 'number0': 6, 'number1': 7, 'number2': 8, 'number3': 9, 'number4': 10, 'number5': 11, 'number6': 12, 'number7': 13, 'number8': 14, 'number9': 15, 'number10': 16, 'number11': 17}\n\t\t\tself.id2w = {0: '<s>', 1: '</s>', 2: '+', 3: '-', 4: '*', 5: '/', 6: 'number0', 7: 'number1', 8: 'number2', 9: 'number3', 10: 'number4', 11: 'number5', 12: 'number6', 13: 'number7', 14: 'number8', 15: 'number9', 16: 'number10', 17: 'number11'}\n\t\t\tself.w2c = {'+': 0, '-': 0, '*': 0, '/': 0, 'number0': 0, 'number1': 0, 'number2': 0, 'number3': 0, 'number4': 0, 'number5': 0, 'number6': 0, 'number7': 0, 'number8': 0, 'number9': 0, 'number10': 0, 'number11': 0}\n\t\t\tself.nwords = 18\n\t\telif config.mawps_vocab:\n\t\t\t# '0.25', '8.0', '0.05', '60.0', '7.0', '5.0', '2.0', '4.0', '1.0', '12.0', '100.0', '25.0', '0.1', '3.0', '0.01', '0.5', '10.0'\n\t\t\tself.w2id = {'<s>': 0, '</s>': 1, '+': 2, '-': 3, '*': 4, '/': 5, 'number0': 6, 'number1': 7, 'number2': 8, 'number3': 9, 'number4': 10, '0.25': 11, '8.0': 12, '0.05': 13, '60.0': 14, '7.0': 15, '5.0': 16, '2.0': 17, '4.0': 18, '1.0': 19, '12.0': 20, '100.0': 21, '25.0': 22, '0.1': 23, '3.0': 24, '0.01': 25, '0.5': 26, '10.0': 27}\n\t\t\tself.id2w = {0: '<s>', 1: '</s>', 2: '+', 3: '-', 4: '*', 5: '/', 6: 'number0', 7: 'number1', 8: 'number2', 9: 'number3', 10: 'number4', 11: '0.25', 12: '8.0', 13: '0.05', 14: '60.0', 15: '7.0', 16: '5.0', 17: '2.0', 18: '4.0', 19: '1.0', 20: '12.0', 21: '100.0', 22: '25.0', 23: '0.1', 24: '3.0', 25: '0.01', 26: '0.5', 27: '10.0'}\n\t\t\tself.w2c = {'+': 0, '-': 0, '*': 0, '/': 0, 'number0': 0, 'number1': 0, 'number2': 0, 'number3': 0, 'number4': 0, '0.25': 0, '8.0': 0, '0.05': 0, '60.0': 0, '7.0': 0, '5.0': 0, '2.0': 0, '4.0': 0, '1.0': 0, '12.0': 0, '100.0': 0, '25.0': 0, '0.1': 0, '3.0': 0, '0.01': 0, '0.5': 0, '10.0': 0}\n\t\t\tself.nwords = 28\n\t\telse:\n\t\t\tself.w2id = {'<s>': 0, '</s>': 1, '+': 2, '-': 3, '*': 4, '/': 5, 'number0': 6, 'number1': 7, 'number2': 8, 'number3': 9, 'number4': 10}\n\t\t\tself.id2w = {0: '<s>', 1: '</s>', 2: '+', 3: '-', 4: '*', 5: '/', 6: 'number0', 7: 'number1', 8: 'number2', 9: 'number3', 10: 'number4'}\n\t\t\tself.w2c = {'+': 0, '-': 0, '*': 0, '/': 0, 'number0': 0, 'number1': 0, 'number2': 0, 'number3': 0, 'number4': 0}\n\t\t\tself.nwords = 11\n\n\tdef add_word(self, word):\n\t\tif word not in self.w2id: # IT SHOULD NEVER GO HERE!!\n\t\t\tself.w2id[word] = self.nwords\n\t\t\tself.id2w[self.nwords] = word\n\t\t\tself.w2c[word] = 1\n\t\t\tself.nwords += 1\n\t\telse:\n\t\t\tself.w2c[word] += 1\n\n\tdef add_sent(self, sent):\n\t\tfor word in sent.split():\n\t\t\tself.add_word(word)\n\n\tdef get_id(self, idx):\n\t\treturn self.w2id[idx]\n\n\tdef get_word(self, idx):\n\t\treturn self.id2w[idx]\n\n\tdef create_vocab_dict(self, args, train_dataloader):\n\t\tfor data in train_dataloader:\n\t\t\tfor sent in data['eqn']:\n\t\t\t\tself.add_sent(sent)\n\n\t\tassert len(self.w2id) == self.nwords\n\t\tassert len(self.id2w) == self.nwords\n\n\tdef add_to_vocab_dict(self, args, dataloader):\n\t\tfor data in dataloader:\n\t\t\tfor sent in data['eqn']:\n\t\t\t\tself.add_sent(sent)\n\n\t\tassert len(self.w2id) == self.nwords\n\t\tassert len(self.id2w) == self.nwords\n \ndef bleu_scorer(ref, hyp, script='default'):\n\t'''\n\t\tBleu Scorer (Send list of list of references, and a list of hypothesis)\n\t'''\n\trefsend = []\n\tfor i in range(len(ref)):\n\t\trefsi = []\n\t\tfor j in range(len(ref[i])):\n\t\t\trefsi.append(ref[i][j].split())\n\t\trefsend.append(refsi)\n\n\tgensend = []\n\tfor i in range(len(hyp)):\n\t\tgensend.append(hyp[i].split())\n\n\tif script == 'nltk':\n\t\t metrics = corpus_bleu(refsend, gensend)\n\t\t return [metrics]\n\n\tmetrics = compute_bleu(refsend, gensend)\n\treturn metrics\n\n\n##################################################\n# logger.py #\n##################################################\n\n'''Logging Modules'''\n\ndef get_logger(name, log_file_path='./logs/temp.log', logging_level=logging.INFO, log_format='%(asctime)s | %(levelname)s | %(filename)s: %(lineno)s : %(funcName)s() ::\\t %(message)s'):\n\tlogger = logging.getLogger(name)\n\tlogger.setLevel(logging_level)\n\tformatter = logging.Formatter(log_format)\n\n\tfile_handler = logging.FileHandler(log_file_path, mode='w')\n\tfile_handler.setLevel(logging_level)\n\tfile_handler.setFormatter(formatter)\n\n\tstream_handler = logging.StreamHandler()\n\tstream_handler.setLevel(logging_level)\n\tstream_handler.setFormatter(formatter)\n\n\tlogger.addHandler(file_handler)\n\tlogger.addHandler(stream_handler)\n\n\treturn logger\n\ndef print_log(logger, dict):\n\tstring = ''\n\tfor key, value in dict.items():\n\t\tstring += '\\n {}: {}\\t'.format(key.replace('_', ' '), value)\n\tlogger.info(string)\n\ndef store_results(config, max_val_bleu, max_val_acc, min_val_loss, max_train_acc, min_train_loss, best_epoch):\n\ttry:\n\t\twith open(config.result_path) as f:\n\t\t\tres_data =json.load(f)\n\texcept:\n\t\tres_data = {}\n\ttry:\n\t\tmin_train_loss = min_train_loss.item()\n\texcept:\n\t\tpass\n\ttry:\n\t\tmin_val_loss = min_val_loss.item()\n\texcept:\n\t\tpass\n\ttry:\n\t\tdata= {'run name' : str(config.run_name)\n\t\t, 'max val acc': str(max_val_acc)\n\t\t, 'max train acc': str(max_train_acc)\n\t\t, 'max val bleu' : str(max_val_bleu)\n\t\t, 'min val loss' : str(min_val_loss)\n\t\t, 'min train loss': str(min_train_loss)\n\t\t, 'best epoch': str(best_epoch)\n\t\t, 'epochs' : config.epochs\n\t\t, 'dataset' : config.dataset\n\t\t, 'embedding': config.embedding\n\t\t, 'embedding_size': config.emb1_size\n\t\t, 'embedding_lr': config.emb_lr\n\t\t, 'freeze_emb': config.freeze_emb\n\t\t, 'cell_type' : config.cell_type\n\t\t, 'bidirectional' : config.bidirectional\n\t\t, 'hidden_size' : config.hidden_size\n\t\t, 'depth' : config.depth\n\t\t, 'lr' : config.lr\n\t\t, 'batch_size' : config.batch_size\n\t\t, 'dropout' : config.dropout\n\t\t, 'separate optimizers' : config.separate_opt\n\t\t, 'opt' : config.opt\n\t\t}\n\t\tres_data[str(config.run_name)] = data\n\n\t\twith open(config.result_path, 'w', encoding='utf-8') as f:\n\t\t\tjson.dump(res_data, f, ensure_ascii= False, indent= 4)\n\texcept:\n\t\tpdb.set_trace()\n\ndef store_val_results(config, acc_score, folds_scores):\n\ttry:\n\t\twith open(config.val_result_path) as f:\n\t\t\tres_data = json.load(f)\n\texcept:\n\t\tres_data = {}\n\n\ttry:\n\t\tdata= {'run_name' : str(config.run_name)\n\t\t, '5-fold avg acc score' : str(acc_score)\n\t\t, 'Fold0 acc' : folds_scores[0]\n\t\t, 'Fold1 acc' : folds_scores[1]\n\t\t, 'Fold2 acc' : folds_scores[2]\n\t\t, 'Fold3 acc' : folds_scores[3]\n\t\t, 'Fold4 acc' : folds_scores[4]\n\t\t, 'epochs' : config.epochs\n\t\t, 'embedding': config.embedding\n\t\t, 'embedding_size': config.emb1_size\n\t\t, 'embedding_lr': config.emb_lr\n\t\t, 'freeze_emb': config.freeze_emb\n\t\t, 'cell_type' : config.cell_type\n\t\t, 'bidirectional' : config.bidirectional\n\t\t, 'hidden_size' : config.hidden_size\n\t\t, 'depth' : config.depth\n\t\t, 'lr' : config.lr\n\t\t, 'batch_size' : config.batch_size\n\t\t, 'dropout' : config.dropout\n\t\t, 'separate optimizers' : config.separate_opt\n\t\t, 'opt' : config.opt\n\t\t}\n\t\tres_data[str(config.run_name)] = data\n\n\t\twith open(config.val_result_path, 'w', encoding='utf-8') as f:\n\t\t\tjson.dump(res_data, f, ensure_ascii= False, indent= 4)\n\texcept:\n\t\tpdb.set_trace()\n\n\n##################################################\n# sentence_processing.py #\n##################################################\n\ndef sent_to_idx(voc, sent, max_length):\n\tidx_vec = []\n\tfor w in sent.split(' '):\n\t\ttry:\n\t\t\tidx = voc.get_id(w)\n\t\t\tidx_vec.append(idx)\n\t\texcept:\n\t\t\tidx_vec.append(voc.get_id('unk'))\n\t# idx_vec.append(voc.get_id('</s>'))\n\tif len(idx_vec) < max_length-1:\n\t\tidx_vec.append(voc.get_id('</s>'))\n\treturn idx_vec\n\n\ndef sents_to_idx(voc, sents, max_length):\n\tall_indexes = []\n\tfor sent in sents:\n\t\tall_indexes.append(sent_to_idx(voc, sent, max_length))\n\treturn all_indexes\n\n\ndef sent_to_tensor(voc, sentence, device, max_length):\n\tindexes = sent_to_idx(voc, sentence, max_length)\n\treturn torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n\n\ndef batch_to_tensor(voc, sents, device, max_length):\n\tbatch_sent = []\n\t# batch_label = []\n\tfor sent in sents:\n\t\tsent_id = sent_to_tensor(voc, sent, device, max_length)\n\t\tbatch_sent.append(sent_id)\n\n\treturn batch_sent\n\n\ndef idx_to_sent(voc, tensor, no_eos=False):\n\tsent_word_list = []\n\tfor idx in tensor:\n\t\tword = voc.get_word(idx.item())\n\t\tif no_eos:\n\t\t\tif word != '</s>':\n\t\t\t\tsent_word_list.append(word)\n\t\t\t# else:\n\t\t\t# \tbreak\n\t\telse:\n\t\t\tsent_word_list.append(word)\n\treturn sent_word_list\n\n\ndef idx_to_sents(voc, tensors, no_eos=False):\n\ttensors = tensors.transpose(0, 1)\n\tbatch_word_list = []\n\tfor tensor in tensors:\n\t\tbatch_word_list.append(idx_to_sent(voc, tensor, no_eos))\n\n\treturn batch_word_list\n\n\ndef pad_seq(seq, max_length, voc):\n\tseq += [voc.get_id('</s>') for i in range(max_length - len(seq))]\n\treturn seq\n\n# def process_single(sent, label, voc, device):\n\ndef sort_by_len(seqs, input_len, device=None, dim=1):\n\torig_idx = list(range(seqs.size(dim)))\n\t# pdb.set_trace()\n\n\t# Index by which sorting needs to be done\n\tsorted_idx = sorted(orig_idx, key=lambda k: input_len[k], reverse=True)\n\tsorted_idx = torch.LongTensor(sorted_idx)\n\tif device:\n\t\tsorted_idx = sorted_idx.to(device)\n\n\tsorted_seqs = seqs.index_select(1, sorted_idx)\n\tsorted_lens = [input_len[i] for i in sorted_idx]\n\n\t# For restoring original order\n\torig_idx = sorted(orig_idx, key=lambda k: sorted_idx[k])\n\torig_idx = torch.LongTensor(orig_idx)\n\tif device:\n\t\torig_idx = orig_idx.to(device)\n\treturn sorted_seqs, sorted_lens, orig_idx\n\n\ndef restore_order(seqs, input_len, orig_idx):\n\torig_seqs= [seqs[i] for i in orig_idx]\n\torig_lens= [input_len[i] for i in orig_idx]\n\treturn orig_seqs, orig_lens\n\n\ndef process_batch(sent1s, sent2s, voc1, voc2, device):\n\tinput_len1 = [len(s) for s in sent1s]\n\tinput_len2 = [len(s) for s in sent2s]\n\tmax_length_1 = max(input_len1)\n\tmax_length_2 = max(input_len2)\n\n\tsent1s_padded = [pad_seq(s, max_length_1, voc1) for s in sent1s]\n\tsent2s_padded = [pad_seq(s, max_length_2, voc2) for s in sent2s]\n\n\t# Convert to [Max_len X Batch]\n\tsent1_var = Variable(torch.LongTensor(sent1s_padded)).transpose(0, 1)\n\tsent2_var = Variable(torch.LongTensor(sent2s_padded)).transpose(0, 1)\n\n\tsent1_var = sent1_var.to(device)\n\tsent2_var = sent2_var.to(device)\n\n\treturn sent1_var, sent2_var, input_len1, input_len2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:31:09.371396Z","iopub.execute_input":"2024-11-13T06:31:09.371884Z","iopub.status.idle":"2024-11-13T06:31:09.506881Z","shell.execute_reply.started":"2024-11-13T06:31:09.371824Z","shell.execute_reply":"2024-11-13T06:31:09.505836Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## dataloader.py","metadata":{}},{"cell_type":"code","source":"class TextDataset(Dataset):\n\t'''\n\t\tExpecting csv files with columns ['sent1', 'sent2']\n\n\t\tArgs:\n\t\t\t\t\t\tdata_path: Root folder Containing all the data\n\t\t\t\t\t\tdataset: Specific Folder==> data_path/dataset/\t(Should contain train.csv and dev.csv)\n\t\t\t\t\t\tmax_length: Self Explanatory\n\t\t\t\t\t\tis_debug: Load a subset of data for faster testing\n\t\t\t\t\t\tis_train: \n\n\t'''\n\n\tdef __init__(self, data_path='./kaggle/input/svamp-data/data/', dataset='mawps', datatype='train', max_length=30, is_debug=False, is_train=False, grade_info=False, type_info=False, challenge_info=False):\n\t\tif datatype=='train':\n\t\t\tfile_path = os.path.join(data_path, dataset, 'train.csv')\n\t\telif datatype=='dev':\n\t\t\tfile_path = os.path.join(data_path, dataset, 'dev.csv')\n\t\telse:\n\t\t\tfile_path = os.path.join(data_path, dataset, 'dev.csv')\n\n\t\tif grade_info:\n\t\t\tself.grade_info = True\n\t\telse:\n\t\t\tself.grade_info = False\n\n\t\tif type_info:\n\t\t\tself.type_info = True\n\t\telse:\n\t\t\tself.type_info = False\n\n\t\tif challenge_info:\n\t\t\tself.challenge_info = True\n\t\telse:\n\t\t\tself.challenge_info = False\n\n\t\tfile_df= pd.read_csv(file_path)\n\n\t\tself.ques= file_df['Question'].values\n\t\tself.eqn= file_df['Equation'].values\n\t\tself.nums= file_df['Numbers'].values\n\t\tself.ans= file_df['Answer'].values\n\n\t\tif grade_info:\n\t\t\tself.grade = file_df['Grade'].values\n\n\t\tif type_info:\n\t\t\tself.type = file_df['Type'].values\n\n\t\tif challenge_info:\n\t\t\tself.type = file_df['Type'].values\n\t\t\tself.var_type = file_df['Variation Type'].values\n\t\t\tself.annotator = file_df['Annotator'].values\n\t\t\tself.alternate = file_df['Alternate'].values\n\n\t\tif is_debug:\n\t\t\tself.ques= self.ques[:5000:500]\n\t\t\tself.eqn= self.eqn[:5000:500]\n\n\t\tself.max_length= max_length\n\n\t\tif grade_info and type_info:\n\t\t\tall_sents = zip(self.ques, self.eqn, self.nums, self.ans, self.grade, self.type)\n\t\telif grade_info and not type_info:\n\t\t\tall_sents = zip(self.ques, self.eqn, self.nums, self.ans, self.grade)\n\t\telif type_info and not grade_info:\n\t\t\tall_sents = zip(self.ques, self.eqn, self.nums, self.ans, self.type)\n\t\telif challenge_info:\n\t\t\tall_sents = zip(self.ques, self.eqn, self.nums, self.ans, self.type, self.var_type, self.annotator, self.alternate)\n\t\telse:\n\t\t\tall_sents = zip(self.ques, self.eqn, self.nums, self.ans)\n\n\t\tif is_train:\n\t\t\tall_sents = sorted(all_sents, key = lambda x : len(x[0].split()))\n\n\t\tif grade_info and type_info:\n\t\t\tself.ques, self.eqn, self.nums, self.ans, self.grade, self.type = zip(*all_sents)\n\t\telif grade_info and not type_info:\n\t\t\tself.ques, self.eqn, self.nums, self.ans, self.grade = zip(*all_sents)\n\t\telif type_info and not grade_info:\n\t\t\tself.ques, self.eqn, self.nums, self.ans, self.type = zip(*all_sents)\n\t\telif challenge_info:\n\t\t\tself.ques, self.eqn, self.nums, self.ans, self.type, self.var_type, self.annotator, self.alternate = zip(*all_sents)\n\t\telse:\n\t\t\tself.ques, self.eqn, self.nums, self.ans = zip(*all_sents)\n\n\tdef __len__(self):\n\t\treturn len(self.ques)\n\n\tdef __getitem__(self, idx):\n\t\tques = self.process_string(str(self.ques[idx]))\n\t\teqn = self.process_string(str(self.eqn[idx]))\n\t\tnums = self.nums[idx]\n\t\tans = self.ans[idx]\n\n\t\tif self.grade_info and self.type_info:\n\t\t\tgrade = self.grade[idx]\n\t\t\ttype1 = self.type[idx]\n\t\t\treturn {'ques': self.curb_to_length(ques), 'eqn': self.curb_to_length(eqn), 'nums': nums, 'ans': ans, 'grade': grade, \n\t\t\t\t\t'type': type1}\n\t\telif self.grade_info and not self.type_info:\n\t\t\tgrade = self.grade[idx]\n\t\t\treturn {'ques': self.curb_to_length(ques), 'eqn': self.curb_to_length(eqn), 'nums': nums, 'ans': ans, 'grade': grade}\n\t\telif self.type_info and not self.grade_info:\n\t\t\ttype1 = self.type[idx]\n\t\t\treturn {'ques': self.curb_to_length(ques), 'eqn': self.curb_to_length(eqn), 'nums': nums, 'ans': ans, 'type': type1}\n\t\telif self.challenge_info:\n\t\t\ttype1 = self.type[idx]\n\t\t\tvar_type = self.var_type[idx]\n\t\t\tannotator = self.annotator[idx]\n\t\t\talternate = self.alternate[idx]\n\t\t\treturn {'ques': self.curb_to_length(ques), 'eqn': self.curb_to_length(eqn), 'nums': nums, 'ans': ans, 'type': type1, \n\t\t\t\t\t'var_type': var_type, 'annotator': annotator, 'alternate': alternate}\n\t\n\t\treturn {'ques': self.curb_to_length(ques), 'eqn': self.curb_to_length(eqn), 'nums': nums, 'ans': ans}\n\n\tdef curb_to_length(self, string):\n\t\treturn ' '.join(string.strip().split()[:self.max_length])\n\n\tdef process_string(self, string):\n\t\t#string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n\t\tstring = re.sub(r\"\\'s\", \" 's\", string)\n\t\tstring = re.sub(r\"\\'ve\", \" 've\", string)\n\t\tstring = re.sub(r\"n\\'t\", \" n't\", string)\n\t\tstring = re.sub(r\"\\'re\", \" 're\", string)\n\t\tstring = re.sub(r\"\\'d\", \" 'd\", string)\n\t\tstring = re.sub(r\"\\'ll\", \" 'll\", string)\n\t\t#string = re.sub(r\",\", \" , \", string)\n\t\t#string = re.sub(r\"!\", \" ! \", string)\n\t\t#string = re.sub(r\"\\(\", \" ( \", string)\n\t\t#string = re.sub(r\"\\)\", \" ) \", string)\n\t\t#string = re.sub(r\"\\?\", \" ? \", string)\n\t\t#string = re.sub(r\"\\s{2,}\", \" \", string)\n\t\treturn string","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:31:09.509133Z","iopub.execute_input":"2024-11-13T06:31:09.509529Z","iopub.status.idle":"2024-11-13T06:31:09.540536Z","shell.execute_reply.started":"2024-11-13T06:31:09.509485Z","shell.execute_reply":"2024-11-13T06:31:09.539288Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## modelv2.py","metadata":{}},{"cell_type":"code","source":"class Seq2SeqModel(nn.Module):\n\tdef __init__(self, config, voc1, voc2, device, logger, num_iters, EOS_tag='</s>', SOS_tag='<s>'):\n\t\tsuper(Seq2SeqModel, self).__init__()\n\n\t\tself.config = config\n\t\tself.device = device\n\t\tself.voc1 = voc1\n\t\tself.voc2 = voc2\n\t\tself.EOS_tag = EOS_tag\n\t\tself.SOS_tag = SOS_tag\n\t\tself.EOS_token = voc2.get_id(EOS_tag)\n\t\tself.SOS_token = voc2.get_id(SOS_tag)\n\t\tself.logger = logger\n\t\tself.num_iters = num_iters\n\n\t\tself.embedding2 = nn.Embedding(self.voc2.nwords, self.config.emb2_size)\n\t\tnn.init.uniform_(self.embedding2.weight, -1 * self.config.init_range, self.config.init_range)\n\n\t\tif self.config.embedding == 'bert':\n\t\t\tself.embedding1 = BertEncoder(self.config.emb_name, self.device, self.config.freeze_emb)\n\t\telif self.config.embedding == 'roberta':\n\t\t\tself.embedding1 = RobertaEncoder(self.config.emb_name, self.device, self.config.freeze_emb)\n\t\telif self.config.embedding == 'word2vec':\n\t\t\tself.config.emb1_size = 300\n\t\t\tself.embedding1 = nn.Embedding.from_pretrained(torch.FloatTensor(self._form_embeddings(self.config.word2vec_bin)), freeze = self.config.freeze_emb)\n\t\telse:\n\t\t\tself.embedding1  = nn.Embedding(self.voc1.nwords, self.config.emb1_size)\n\t\t\tnn.init.uniform_(self.embedding1.weight, -1 * self.config.init_range, self.config.init_range)\n\n\t\tself.logger.debug('Building Encoders...')\n\t\tself.encoder = Encoder(\n\t\t\tself.config.hidden_size,\n\t\t\tself.config.emb1_size,\n\t\t\tself.config.cell_type,\n\t\t\tself.config.depth,\n\t\t\tself.config.dropout,\n\t\t\tself.config.bidirectional\n\t\t)\n\n\t\tself.logger.debug('Encoders Built...')\n\n\t\tif self.config.use_attn:\n\t\t\tself.decoder    = LuongAttnDecoderRNN(self.config.attn_type,\n\t\t\t\t\t\t\t\t\t\t\t\t  self.embedding2,\n\t\t\t\t\t\t\t\t\t\t\t\t  self.config.cell_type,\n\t\t\t\t\t\t\t\t\t\t\t\t  self.config.hidden_size,\n\t\t\t\t\t\t\t\t\t\t\t\t  self.voc2.nwords,\n\t\t\t\t\t\t\t\t\t\t\t\t  self.config.depth,\n\t\t\t\t\t\t\t\t\t\t\t\t  self.config.dropout).to(device)\n\t\telse:\n\t\t\tself.decoder    = DecoderRNN(self.embedding2,\n\t\t\t\t\t\t\t\t\t\t self.config.cell_type,\n\t\t\t\t\t\t\t\t\t\t self.config.hidden_size,\n\t\t\t\t\t\t\t\t\t\t self.voc2.nwords,\n\t\t\t\t\t\t\t\t\t\t self.config.depth,\n\t\t\t\t\t\t\t\t\t\t self.config.dropout).to(device)\n\n\t\tself.logger.debug('Decoder RNN Built...')\n\n\t\tself.logger.debug('Initalizing Optimizer and Criterion...')\n\t\tself._initialize_optimizer()\n\n\t\t# nn.CrossEntropyLoss() does both F.log_softmax() and nn.NLLLoss() \n\t\tself.criterion = nn.NLLLoss() \n\n\t\tself.logger.info('All Model Components Initialized...')\n\n\tdef _form_embeddings(self, file_path):\n\t\tweights_all = models.KeyedVectors.load_word2vec_format(file_path, limit=200000, binary=True)\n\t\tweight_req  = torch.randn(self.voc1.nwords, self.config.emb1_size)\n\t\tfor key, value in self.voc1.id2w.items():\n\t\t\tif value in weights_all:\n\t\t\t\tweight_req[key] = torch.FloatTensor(weights_all[value])\n\n\t\treturn weight_req\t\n\n\tdef _initialize_optimizer(self):\n\t\tself.params =   list(self.embedding1.parameters()) + \\\n\t\t\t\t\t\tlist(self.encoder.parameters()) + \\\n\t\t\t\t\t\tlist(self.decoder.parameters())\n\n\t\tif self.config.separate_opt:\n\t\t\tself.emb_optimizer = AdamW(self.embedding1.parameters(), lr = self.config.emb_lr, correct_bias = True)\n\t\t\tself.optimizer = optim.Adam(\n\t\t\t\t[{\"params\": self.encoder.parameters()},\n\t\t\t\t{\"params\": self.decoder.parameters()}],\n\t\t\t\tlr = self.config.lr,\n\t\t\t)\n\t\telse:\n\t\t\tif self.config.opt == 'adam':\n\t\t\t\tself.optimizer = optim.Adam(\n\t\t\t\t\t[{\"params\": self.embedding1.parameters(), \"lr\": self.config.emb_lr},\n\t\t\t\t\t{\"params\": self.encoder.parameters()},\n\t\t\t\t\t{\"params\": self.decoder.parameters()}],\n\t\t\t\t\tlr = self.config.lr\n\t\t\t\t)\n\t\t\telif self.config.opt == 'adadelta':\n\t\t\t\tself.optimizer = optim.Adadelta(\n\t\t\t\t\t[{\"params\": self.embedding1.parameters(), \"lr\": self.config.emb_lr},\n\t\t\t\t\t{\"params\": self.encoder.parameters()},\n\t\t\t\t\t{\"params\": self.decoder.parameters()}],\n\t\t\t\t\tlr = self.config.lr\n\t\t\t\t)\n\t\t\telif self.config.opt == 'asgd':\n\t\t\t\tself.optimizer = optim.ASGD(\n\t\t\t\t\t[{\"params\": self.embedding1.parameters(), \"lr\": self.config.emb_lr},\n\t\t\t\t\t{\"params\": self.encoder.parameters()},\n\t\t\t\t\t{\"params\": self.decoder.parameters()}],\n\t\t\t\t\tlr = self.config.lr\n\t\t\t\t)\n\t\t\telse:\n\t\t\t\tself.optimizer = optim.SGD(\n\t\t\t\t\t[{\"params\": self.embedding1.parameters(), \"lr\": self.config.emb_lr},\n\t\t\t\t\t{\"params\": self.encoder.parameters()},\n\t\t\t\t\t{\"params\": self.decoder.parameters()}],\n\t\t\t\t\tlr = self.config.lr\n\t\t\t\t)\n\n\tdef forward(self, input_seq1, input_seq2, input_len1, input_len2):\n\t\t'''\n\t\t\tArgs:\n\t\t\t\tinput_seq1 (tensor): values are word indexes | size : [max_len x batch_size]\n\t\t\t\tinput_len1 (tensor): Length of each sequence in input_len1 | size : [batch_size]\n\t\t\t\tinput_seq2 (tensor): values are word indexes | size : [max_len x batch_size]\n\t\t\t\tinput_len2 (tensor): Length of each sequence in input_len2 | size : [batch_size]\n\t\t\tReturns:\n\t\t\t\tout (tensor) : Probabilities of each output label for each point | size : [batch_size x num_labels]\n\t\t'''\n\n\tdef trainer(self, ques, input_seq1, input_seq2, input_len1, input_len2, config, device=None ,logger=None):\n\t\t'''\n\t\t\tArgs:\n\t\t\t\tques (list): input examples as is (i.e. not indexed) | size : [batch_size]\n\t\t\tReturns:\n\t\t\t\t\n\t\t'''\n\t\tself.optimizer.zero_grad()\n\t\tif self.config.separate_opt:\n\t\t\tself.emb_optimizer.zero_grad()\n\n\t\tif self.config.embedding == 'bert' or self.config.embedding == 'roberta':\n\t\t\tinput_seq1, input_len1 = self.embedding1(ques)\n\t\t\tinput_seq1 = input_seq1.transpose(0,1)\n\t\t\t# input_seq1: Tensor [max_len x BS x emb1_size]\n\t\t\t# input_len1: List [BS]\n\t\t\tsorted_seqs, sorted_len, orig_idx = sort_by_len(input_seq1, input_len1, self.device)\n\t\t\t# sorted_seqs: Tensor [max_len x BS x emb1_size]\n\t\t\t# input_len1: List [BS]\n\t\t\t# orig_idx: Tensor [BS]\n\t\telse:\n\t\t\tsorted_seqs, sorted_len, orig_idx = sort_by_len(input_seq1, input_len1, self.device)\n\t\t\t# sorted_seqs: Tensor [max_len x BS]\n\t\t\tsorted_seqs = self.embedding1(sorted_seqs)\n\n\t\tencoder_outputs, encoder_hidden = self.encoder(sorted_seqs, sorted_len, orig_idx, self.device)\n\n\t\tencoder_hidden_single = encoder_hidden\n\t\tif self.config.depth > 1:\n\t\t\tfor z in range(self.config.depth-1):\n\t\t\t\tencoder_hidden = torch.cat((encoder_hidden, encoder_hidden_single), dim = 0)\n\t\t\n\t\tself.loss =0\n\n\t\tdecoder_input = torch.tensor([self.SOS_token for i in range(input_seq1.size(1))], device = self.device)\n\n\t\tif config.cell_type == 'lstm':\n\t\t\t# decoder_hidden = (encoder_hidden[0][:self.decoder.nlayers], encoder_hidden[1][:self.decoder.nlayers])\n\t\t\tdecoder_hidden = (encoder_hidden.to(self.device), torch.zeros(encoder_hidden.size()[0], encoder_hidden.size()[1], encoder_hidden.size()[2], device = self.device))\n\t\telse:\n\t\t\t# decoder_hidden = encoder_hidden[:self.decoder.nlayers]\n\t\t\tdecoder_hidden = encoder_hidden.to(self.device)\n\n\t\tuse_teacher_forcing = True if random.random() < self.config.teacher_forcing_ratio else False\n\t\ttarget_len = max(input_len2)\n\n\t\tif use_teacher_forcing:\n\t\t\tfor step in range(target_len):\n\t\t\t\tif self.config.use_attn:\n\t\t\t\t\tdecoder_output, decoder_hidden, decoder_attention, _ = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n\t\t\t\telse:\n\t\t\t\t\tdecoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n\t\t\t\tself.loss += self.criterion(decoder_output, input_seq2[step])\n\t\t\t\tdecoder_input = input_seq2[step]\n\t\telse:\n\t\t\tfor step in range(target_len):\n\t\t\t\tif self.config.use_attn:\n\t\t\t\t\tdecoder_output, decoder_hidden, decoder_attention, _ = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n\t\t\t\telse:\n\t\t\t\t\tdecoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n\t\t\t\t\n\t\t\t\ttopv, topi = decoder_output.topk(1)\n\t\t\t\tself.loss += self.criterion(decoder_output, input_seq2[step])\n\t\t\t\tdecoder_input = topi.squeeze().detach() \n\n\t\tself.loss.backward()\n\t\tif self.config.max_grad_norm > 0:\n\t\t\ttorch.nn.utils.clip_grad_norm_(self.params, self.config.max_grad_norm)\n\t\tself.optimizer.step()\n\t\tif self.config.separate_opt:\n\t\t\tself.emb_optimizer.step()\n\n\t\treturn self.loss.item()/target_len\n\n\tdef greedy_decode(self, ques, input_seq1=None, input_seq2=None, input_len1=None, input_len2=None, validation=False, return_probs = False):\n\t\twith torch.no_grad():\n\t\t\tif self.config.embedding == 'bert' or self.config.embedding == 'roberta':\n\t\t\t\tinput_seq1, input_len1 = self.embedding1(ques)\n\t\t\t\tinput_seq1 = input_seq1.transpose(0,1)\n\t\t\t\tsorted_seqs, sorted_len, orig_idx = sort_by_len(input_seq1, input_len1, self.device)\n\t\t\telse:\n\t\t\t\tsorted_seqs, sorted_len, orig_idx = sort_by_len(input_seq1, input_len1, self.device)\n\t\t\t\tsorted_seqs = self.embedding1(sorted_seqs)\n\n\t\t\tencoder_outputs, encoder_hidden = self.encoder(sorted_seqs, sorted_len, orig_idx, self.device)\n\n\t\t\tencoder_hidden_single = encoder_hidden\n\t\t\tif self.config.depth > 1:\n\t\t\t\tfor z in range(self.config.depth-1):\n\t\t\t\t\tencoder_hidden = torch.cat((encoder_hidden, encoder_hidden_single), dim = 0)\n\n\t\t\tloss = 0.0\n\t\t\tdecoder_input = torch.tensor([self.SOS_token for i in range(input_seq1.size(1))], device=self.device)\n\n\t\t\tif self.config.cell_type == 'lstm':\n\t\t\t\t# decoder_hidden = (encoder_hidden[0][:self.decoder.nlayers], encoder_hidden[1][:self.decoder.nlayers])\n\t\t\t\tdecoder_hidden = (encoder_hidden.to(self.device), torch.zeros(encoder_hidden.size()[0], encoder_hidden.size()[1], encoder_hidden.size()[2], device = self.device))\n\t\t\telse:\n\t\t\t\t# decoder_hidden = encoder_hidden[:self.decoder.nlayers]\n\t\t\t\tdecoder_hidden = encoder_hidden.to(self.device)\n\n\t\t\tdecoded_words = [[] for i in range(input_seq1.size(1))]\n\t\t\tdecoded_probs = [[] for i in range(input_seq1.size(1))]\n\t\t\tdecoder_attentions = []\n\n\t\t\tif validation:\n\t\t\t\ttarget_len = max(input_len2)\n\t\t\telse:\n\t\t\t\ttarget_len = self.config.max_length\n\n\t\t\tfor step in range(target_len):\n\t\t\t\tif self.config.use_attn:\n\t\t\t\t\tdecoder_output, decoder_hidden, decoder_attention, _ = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n\t\t\t\t\tdecoder_attentions.append(decoder_attention.squeeze(1).tolist())\n\t\t\t\telse:\n\t\t\t\t\tdecoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n\n\t\t\t\tif validation:\n\t\t\t\t\tloss += self.criterion(decoder_output, input_seq2[step])\n\t\t\t\ttopv, topi = decoder_output.topk(1)\n\t\t\t\tfor i in range(input_seq1.size(1)):\n\t\t\t\t\tif topi[i].item() == self.EOS_token:\n\t\t\t\t\t\tcontinue\n\t\t\t\t\tdecoded_words[i].append(self.voc2.get_word(topi[i].item()))\n\t\t\t\t\tdecoded_probs[i].append(topv[i].item())\n\t\t\t\tif topi.size()[0] == 1 and topi.size()[1] == 1:\n\t\t\t\t\tdecoder_input = topi.squeeze(0).detach()\n\t\t\t\telse:\n\t\t\t\t\tdecoder_input = topi.squeeze().detach()\n\t\t\t\t\t\n\t\t\tif validation:\n\t\t\t\tif self.config.use_attn:\n\t\t\t\t\treturn loss/target_len, decoded_words, decoder_attentions[:step + 1]\n\t\t\t\telse:\n\t\t\t\t\treturn loss/target_len, decoded_words, None\n\t\t\telse:\n\t\t\t\tif return_probs:\n\t\t\t\t\treturn decoded_words, decoded_probs\n\n\t\t\t\treturn decoded_words, decoder_attentions[:step + 1]\n\n\tdef obtain_hidden(self, config, ques, input_seq1=None, input_seq2=None, input_len1=None, input_len2=None):\n\t\twith torch.no_grad():\n\t\t\tif self.config.embedding == 'bert' or self.config.embedding == 'roberta':\n\t\t\t\tinput_seq1, input_len1 = self.embedding1(ques)\n\t\t\t\tinput_seq1 = input_seq1.transpose(0,1)\n\t\t\t\tsorted_seqs, sorted_len, orig_idx = sort_by_len(input_seq1, input_len1, self.device)\n\t\t\telse:\n\t\t\t\tsorted_seqs, sorted_len, orig_idx = sort_by_len(input_seq1, input_len1, self.device)\n\t\t\t\tsorted_seqs = self.embedding1(sorted_seqs)\n\n\t\t\tencoder_outputs, encoder_hidden = self.encoder(sorted_seqs, sorted_len, orig_idx, self.device)\n\n\t\t\tloss =0.0\n\t\t\tdecoder_input = torch.tensor([self.SOS_token for i in range(input_seq1.size(1))], device=self.device)\n\n\t\t\tif self.config.cell_type == 'lstm':\n\t\t\t\tdecoder_hidden = (encoder_hidden[0][:self.decoder.nlayers], encoder_hidden[1][:self.decoder.nlayers])\n\t\t\telse:\n\t\t\t\tdecoder_hidden = encoder_hidden[:self.decoder.nlayers]\n\n\t\t\tdecoded_words = [[] for i in range(input_seq1.size(1))]\n\t\t\tdecoder_attentions = []\n\n\t\t\thiddens = []\n\n\t\t\ttarget_len = max(input_len2)\n\n\t\t\tfor step in range(target_len):\n\t\t\t\tif self.config.use_attn:\n\t\t\t\t\tdecoder_output, decoder_hidden, decoder_attention, hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n\t\t\t\t\tdecoder_attentions.append(decoder_attention)\n\t\t\t\telse:\n\t\t\t\t\tdecoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n\n\t\t\t\ttopv, topi = decoder_output.topk(1)\n\t\t\t\tfor i in range(input_seq1.size(1)):\n\t\t\t\t\tif topi[i].item() == self.EOS_token:\n\t\t\t\t\t\tcontinue\n\t\t\t\t\tdecoded_words[i].append(self.voc2.get_word(topi[i].item()))\n\t\t\t\t\thiddens.append([self.voc2.get_word(topi[i].item()), hidden[i]])\n\t\t\t\tdecoder_input = topi.squeeze().detach()\n\n\t\t\treturn hiddens, decoded_words\n\ndef build_model(config, voc1, voc2, device, logger, num_iters):\n\t'''\n\t\tAdd Docstring\n\t'''\n\tmodel = Seq2SeqModel(config, voc1, voc2, device, logger, num_iters)\n\tmodel = model.to(device)\n\n\treturn model\n\ndef train_model(model, train_dataloader, val_dataloader, voc1, voc2, device, config, logger, epoch_offset= 0, min_val_loss=float('inf'), max_val_bleu=0.0, max_val_acc = 0.0, min_train_loss=float('inf'), max_train_acc = 0.0, best_epoch = 0, writer= None):\n\t'''\n\t\tAdd Docstring\n\t'''\n\n\tif config.histogram and config.save_writer and writer:\n\t\tfor name, param in model.named_parameters():\n\t\t\twriter.add_histogram(name, param, epoch_offset)\n\t\n\testop_count=0\n\t\n\tfor epoch in range(1, config.epochs + 1):\n\t\tod = OrderedDict()\n\t\tod['Epoch'] = epoch + epoch_offset\n\t\tprint_log(logger, od)\n\n\t\tbatch_num = 1\n\t\ttrain_loss_epoch = 0.0\n\t\ttrain_acc_epoch = 0.0\n\t\ttrain_acc_epoch_cnt = 0.0\n\t\ttrain_acc_epoch_tot = 0.0\n\t\tval_loss_epoch = 0.0\n\n\t\tstart_time= time()\n\t\ttotal_batches = len(train_dataloader)\n\n\t\tfor data in train_dataloader:\n\t\t\tques = data['ques']\n\n\t\t\tsent1s = sents_to_idx(voc1, data['ques'], config.max_length)\n\t\t\tsent2s = sents_to_idx(voc2, data['eqn'], config.max_length)\n\t\t\tsent1_var, sent2_var, input_len1, input_len2  = process_batch(sent1s, sent2s, voc1, voc2, device)\n\n\t\t\tnums = data['nums']\n\t\t\tans = data['ans']\n\n\t\t\tmodel.train()\n\n\t\t\tloss = model.trainer(ques, sent1_var, sent2_var, input_len1, input_len2, config, device, logger)\n\t\t\ttrain_loss_epoch += loss\n\n\t\t\tif config.show_train_acc:\n\t\t\t\tmodel.eval()\n\n\t\t\t\t_, decoder_output, _ = model.greedy_decode(ques, sent1_var, sent2_var, input_len1, input_len2, validation=True)\n\t\t\t\ttemp_acc_cnt, temp_acc_tot, _ = cal_score(decoder_output, nums, ans)\n\t\t\t\ttrain_acc_epoch_cnt += temp_acc_cnt\n\t\t\t\ttrain_acc_epoch_tot += temp_acc_tot\n\n\t\t\tbatch_num+=1\n\t\t\tprint(\"Completed {} / {}...\".format(batch_num, total_batches), end = '\\r', flush = True)\n\n\t\ttrain_loss_epoch = train_loss_epoch/len(train_dataloader)\n\t\tif config.show_train_acc:\n\t\t\ttrain_acc_epoch = train_acc_epoch_cnt/train_acc_epoch_tot\n\t\telse:\n\t\t\ttrain_acc_epoch = 0.0\n\n\t\ttime_taken = (time() - start_time)/60.0\n\n\t\tif config.save_writer and writer:\n\t\t\twriter.add_scalar('loss/train_loss', train_loss_epoch, epoch + epoch_offset)\n\n\t\tlogger.debug('Training for epoch {} completed...\\nTime Taken: {}'.format(epoch, time_taken))\n\t\tlogger.debug('Starting Validation')\n\n\t\tval_bleu_epoch, val_loss_epoch, val_acc_epoch, val_attn_wts = run_validation(config=config, model=model, dataloader=val_dataloader, voc1=voc1, voc2=voc2, device=device, logger=logger, epoch_num = epoch)\n\n\t\tif train_loss_epoch < min_train_loss:\n\t\t\tmin_train_loss = train_loss_epoch\n\n\t\tif train_acc_epoch > max_train_acc:\n\t\t\tmax_train_acc = train_acc_epoch\n\n\t\tif val_bleu_epoch[0] > max_val_bleu:\n\t\t\tmax_val_bleu = val_bleu_epoch[0]\n\n\t\tif val_loss_epoch < min_val_loss:\n\t\t\tmin_val_loss = val_loss_epoch\n\n\t\tif val_acc_epoch > max_val_acc:\n\t\t\tmax_val_acc = val_acc_epoch\n\t\t\tbest_epoch = epoch + epoch_offset\n\n\t\t\tattn_path = os.path.join(config.outputs_path, 'attn.p')\n\t\t\twith open(attn_path, 'wb') as f:\n\t\t\t\tpickle.dump(val_attn_wts, f, protocol=pickle.HIGHEST_PROTOCOL)\n\n\t\t\tif config.separate_opt:\n\t\t\t\tstate = {\n\t\t\t\t\t'epoch' : epoch + epoch_offset,\n\t\t\t\t\t'best_epoch': best_epoch,\n\t\t\t\t\t'model_state_dict': model.state_dict(),\n\t\t\t\t\t'voc1': model.voc1,\n\t\t\t\t\t'voc2': model.voc2,\n\t\t\t\t\t'optimizer_state_dict': model.optimizer.state_dict(),\n\t\t\t\t\t'emb_optimizer_state_dict': model.emb_optimizer.state_dict(),\n\t\t\t\t\t'train_loss_epoch' : train_loss_epoch,\n\t\t\t\t\t'min_train_loss' : min_train_loss,\n\t\t\t\t\t'train_acc_epoch' : train_acc_epoch,\n\t\t\t\t\t'max_train_acc' : max_train_acc,\n\t\t\t\t\t'val_loss_epoch' : val_loss_epoch,\n\t\t\t\t\t'min_val_loss' : min_val_loss,\n\t\t\t\t\t'val_acc_epoch' : val_acc_epoch,\n\t\t\t\t\t'max_val_acc' : max_val_acc,\n\t\t\t\t\t'val_bleu_epoch': val_bleu_epoch[0],\n\t\t\t\t\t'max_val_bleu': max_val_bleu\n\t\t\t\t}\n\t\t\telse:\n\t\t\t\tstate = {\n\t\t\t\t\t'epoch' : epoch + epoch_offset,\n\t\t\t\t\t'best_epoch': best_epoch,\n\t\t\t\t\t'model_state_dict': model.state_dict(),\n\t\t\t\t\t'voc1': model.voc1,\n\t\t\t\t\t'voc2': model.voc2,\n\t\t\t\t\t'optimizer_state_dict': model.optimizer.state_dict(),\n\t\t\t\t\t'train_loss_epoch' : train_loss_epoch,\n\t\t\t\t\t'min_train_loss' : min_train_loss,\n\t\t\t\t\t'train_acc_epoch' : train_acc_epoch,\n\t\t\t\t\t'max_train_acc' : max_train_acc,\n\t\t\t\t\t'val_loss_epoch' : val_loss_epoch,\n\t\t\t\t\t'min_val_loss' : min_val_loss,\n\t\t\t\t\t'val_acc_epoch' : val_acc_epoch,\n\t\t\t\t\t'max_val_acc' : max_val_acc,\n\t\t\t\t\t'val_bleu_epoch': val_bleu_epoch[0],\n\t\t\t\t\t'max_val_bleu': max_val_bleu\n\t\t\t\t}\n\t\t\tlogger.debug('Validation Bleu: {}'.format(val_bleu_epoch[0]))\n\n\t\t\tif config.save_model:\n\t\t\t\tsave_checkpoint(state, epoch + epoch_offset, logger, config.model_path, config.ckpt)\n\t\t\testop_count = 0\n\t\telse:\n\t\t\testop_count+=1\n\n\t\tif config.save_writer and writer:\n\t\t\twriter.add_scalar('loss/val_loss', val_loss_epoch, epoch + epoch_offset)\n\t\t\twriter.add_scalar('acc/val_score', val_bleu_epoch[0], epoch + epoch_offset)\n\n\t\tod = OrderedDict()\n\t\tod['Epoch'] = epoch + epoch_offset\n\t\tod['best_epoch'] = best_epoch\n\t\tod['train_loss_epoch'] = train_loss_epoch\n\t\tod['min_train_loss'] = min_train_loss\n\t\tod['val_loss_epoch']= val_loss_epoch\n\t\tod['min_val_loss']= min_val_loss\n\t\tod['train_acc_epoch'] = train_acc_epoch\n\t\tod['max_train_acc'] = max_train_acc\n\t\tod['val_acc_epoch'] = val_acc_epoch\n\t\tod['max_val_acc'] = max_val_acc\n\t\tod['val_bleu_epoch'] = val_bleu_epoch\n\t\tod['max_val_bleu'] = max_val_bleu\n\t\tprint_log(logger, od)\n\n\t\tif config.histogram and config.save_writer and writer:\n\t\t\tfor name, param in model.named_parameters():\n\t\t\t\twriter.add_histogram(name, param, epoch + epoch_offset)\n\n\t\tif estop_count > config.early_stopping:\n\t\t\tlogger.debug('Early Stopping at Epoch: {} after no improvement in {} epochs'.format(epoch, estop_count))\n\t\t\tbreak\n\n\tif config.save_writer:\n\t\twriter.export_scalars_to_json(os.path.join(config.board_path, 'all_scalars.json'))\n\t\twriter.close()\n\n\tlogger.info('Training Completed for {} epochs'.format(config.epochs))\n\n\tif config.results:\n\t\tstore_results(config, max_val_bleu, max_val_acc, min_val_loss, max_train_acc, min_train_loss, best_epoch)\n\t\tlogger.info('Scores saved at {}'.format(config.result_path))\n\n\treturn max_val_acc\n\ndef run_validation(config, model, dataloader, voc1, voc2, device, logger, epoch_num):\n\tbatch_num = 1\n\tval_loss_epoch = 0.0\n\tval_bleu_epoch = 0.0\n\tval_acc_epoch = 0.0\n\tval_acc_epoch_cnt = 0.0\n\tval_acc_epoch_tot = 0.0\n\n\tmodel.eval()\n\n\trefs= []\n\thyps= []\n\n\tif config.mode == 'test':\n\t\tquestions, gen_eqns, act_eqns, scores = [], [], [], []\n\n\tdisplay_n = config.batch_size\n\n\tattn_wts_ls = []\n\n\twith open(config.outputs_path + '/outputs.txt', 'a') as f_out:\n\t\tf_out.write('---------------------------------------\\n')\n\t\tf_out.write('Epoch: ' + str(epoch_num) + '\\n')\n\t\tf_out.write('---------------------------------------\\n')\n\ttotal_batches = len(dataloader)\n\tfor data in dataloader:\n\t\tsent1s = sents_to_idx(voc1, data['ques'], config.max_length)\n\t\tsent2s = sents_to_idx(voc2, data['eqn'], config.max_length)\n\t\tnums = data['nums']\n\t\tans = data['ans']\n\t\tif config.grade_disp:\n\t\t\tgrade = data['grade']\n\t\tif config.type_disp:\n\t\t\ttype1 = data['type']\n\t\tif config.challenge_disp:\n\t\t\ttype1 = data['type']\n\t\t\tvar_type = data['var_type']\n\t\t\tannotator = data['annotator']\n\t\t\talternate = data['alternate']\n\n\t\tques = data['ques']\n\n\t\tsent1_var, sent2_var, input_len1, input_len2 = process_batch(sent1s, sent2s, voc1, voc2, device)\n\n\t\tval_loss, decoder_output, decoder_attn = model.greedy_decode(ques, sent1_var, sent2_var, input_len1, input_len2, validation=True)\n\n\t\ttemp_acc_cnt, temp_acc_tot, disp_corr = cal_score(decoder_output, nums, ans)\n\t\tval_acc_epoch_cnt += temp_acc_cnt\n\t\tval_acc_epoch_tot += temp_acc_tot\n\n\t\tfor yz in range(len(decoder_output)):\n\t\t\tif disp_corr[yz] == 1 and len(decoder_output[yz]) == 3:\n\t\t\t\tattn_wts_ls.append([data['ques'][yz], data['eqn'][yz], decoder_attn[0][yz]])\n\n\t\tsent1s = idx_to_sents(voc1, sent1_var, no_eos= True)\n\t\tsent2s = idx_to_sents(voc2, sent2_var, no_eos= True)\n\n\t\trefs += [[' '.join(sent2s[i])] for i in range(sent2_var.size(1))]\n\t\thyps += [' '.join(decoder_output[i]) for i in range(sent1_var.size(1))]\n\n\t\tif config.mode == 'test':\n\t\t\tquestions+= data['ques']\n\t\t\tgen_eqns += [' '.join(decoder_output[i]) for i in range(sent1_var.size(1))]\n\t\t\tact_eqns += [' '.join(sent2s[i]) for i in range(sent2_var.size(1))]\n\t\t\tscores   += [cal_score([decoder_output[i]], [nums[i]], [ans[i]])[0] for i in range(sent1_var.size(1))]\n\n\t\twith open(config.outputs_path + '/outputs.txt', 'a') as f_out:\n\t\t\tf_out.write('Batch: ' + str(batch_num) + '\\n')\n\t\t\tf_out.write('---------------------------------------\\n')\n\t\t\tfor i in range(len(sent1s[:display_n])):\n\t\t\t\ttry:\n\t\t\t\t\tf_out.write('Example: ' + str(i) + '\\n')\n\t\t\t\t\tif config.grade_disp:\n\t\t\t\t\t\tf_out.write('Grade: ' + str(grade[i].item()) + '\\n')\n\t\t\t\t\tif config.type_disp:\n\t\t\t\t\t\tf_out.write('Type: ' + str(type1[i]) + '\\n')\n\t\t\t\t\tf_out.write('Source: ' + stack_to_string(sent1s[i]) + '\\n')\n\t\t\t\t\tf_out.write('Target: ' + stack_to_string(sent2s[i]) + '\\n')\n\t\t\t\t\tf_out.write('Generated: ' + stack_to_string(decoder_output[i]) + '\\n')\n\t\t\t\t\tif config.challenge_disp:\n\t\t\t\t\t\tf_out.write('Type: ' + str(type1[i]) + '\\n')\n\t\t\t\t\t\tf_out.write('Variation Type: ' + str(var_type[i]) + '\\n')\n\t\t\t\t\t\tf_out.write('Annotator: ' + str(annotator[i]) + '\\n')\n\t\t\t\t\t\tf_out.write('Alternate: ' + str(alternate[i].item()) + '\\n')\n\t\t\t\t\tif config.nums_disp:\n\t\t\t\t\t\tsrc_nums = 0\n\t\t\t\t\t\ttgt_nums = 0\n\t\t\t\t\t\tpred_nums = 0\n\t\t\t\t\t\tfor k in range(len(sent1s[i])):\n\t\t\t\t\t\t\tif sent1s[i][k][:6] == 'number':\n\t\t\t\t\t\t\t\tsrc_nums += 1\n\t\t\t\t\t\tfor k in range(len(sent2s[i])):\n\t\t\t\t\t\t\tif sent2s[i][k][:6] == 'number':\n\t\t\t\t\t\t\t\ttgt_nums += 1\n\t\t\t\t\t\tfor k in range(len(decoder_output[i])):\n\t\t\t\t\t\t\tif decoder_output[i][k][:6] == 'number':\n\t\t\t\t\t\t\t\tpred_nums += 1\n\t\t\t\t\t\tf_out.write('Numbers in question: ' + str(src_nums) + '\\n')\n\t\t\t\t\t\tf_out.write('Numbers in Target Equation: ' + str(tgt_nums) + '\\n')\n\t\t\t\t\t\tf_out.write('Numbers in Predicted Equation: ' + str(pred_nums) + '\\n')\n\t\t\t\t\tf_out.write('Result: ' + str(disp_corr[i]) + '\\n' + '\\n')\n\t\t\t\texcept:\n\t\t\t\t\tlogger.warning('Exception: Failed to generate')\n\t\t\t\t\tpdb.set_trace()\n\t\t\t\t\tbreak\n\t\t\tf_out.write('---------------------------------------\\n')\n\t\t\tf_out.close()\n\n\t\tif batch_num % config.display_freq ==0:\n\t\t\tfor i in range(len(sent1s[:display_n])):\n\t\t\t\ttry:\n\t\t\t\t\tod = OrderedDict()\n\t\t\t\t\tlogger.info('-------------------------------------')\n\t\t\t\t\tod['Source'] = ' '.join(sent1s[i])\n\n\t\t\t\t\tod['Target'] = ' '.join(sent2s[i])\n\n\t\t\t\t\tod['Generated'] = ' '.join(decoder_output[i])\n\t\t\t\t\tprint_log(logger, od)\n\t\t\t\t\tlogger.info('-------------------------------------')\n\t\t\t\texcept:\n\t\t\t\t\tlogger.warning('Exception: Failed to generate')\n\t\t\t\t\tpdb.set_trace()\n\t\t\t\t\tbreak\n\n\t\tval_loss_epoch += val_loss\n\t\tbatch_num +=1\n\t\tprint(\"Completed {} / {}...\".format(batch_num, total_batches), end = '\\r', flush = True)\n\n\tval_bleu_epoch = bleu_scorer(refs, hyps)\n\tif config.mode == 'test':\n\t\tresults_df = pd.DataFrame([questions, act_eqns, gen_eqns, scores]).transpose()\n\t\tresults_df.columns = ['Question', 'Actual Equation', 'Generated Equation', 'Score']\n\t\tcsv_file_path = os.path.join(config.outputs_path, config.dataset+'.csv')\n\t\tresults_df.to_csv(csv_file_path, index = False)\n\t\treturn sum(scores)/len(scores)\n\n\tval_acc_epoch = val_acc_epoch_cnt/val_acc_epoch_tot\n\n\treturn val_bleu_epoch, val_loss_epoch/len(dataloader), val_acc_epoch, attn_wts_ls\n\ndef estimate_confidence(config, model, dataloader, logger):\n\t\n\tquestions\t= []\n\tact_eqns \t= []\n\tgen_eqns\t= []\n\tscores\t\t= []\n\tconfs\t\t= []\n\tbatch_num = 0\n\t\n\t#Load training data (Will be useful for similarity based methods)\n\ttrain_df \t= pd.read_csv(os.path.join('data',config.dataset,'train.csv'))\n\ttrain_ques\t= train_df['Question'].values \n\t\n\ttotal_batches = len(dataloader)\n\tlogger.info(\"Beginning estimating confidence based on {} criteria\".format(config.conf))\n\tstart = time()\n\tfor data in dataloader:\n\t\tques, eqn, nums, ans = data['ques'], data['eqn'], data['nums'], data['ans']\n\t\t\n\t\tif config.conf == 'posterior':\n\t\t\tdecoded_words, confidence = posterior_based_conf(ques, model)\n\t\telif config.conf == 'similarity':\n\t\t\tdecoded_words, confidence = similarity_based_conf(ques, train_ques, model, sim_criteria= config.sim_criteria)\n\t\telse:\n\t\t\t#TODO: Implement other methods\n\t\t\traise ValueError(\"Other confidence methods not implemented yet. Use -conf posterior\")\n\t\t\n\t\tif not config.adv:\n\t\t\tcorrect_or_not = [cal_score([decoded_words[i]], [nums[i]], [ans[i]])[0] for i in range(len(decoded_words))]\n\t\telse:\n\t\t\tcorrect_or_not = [-1 for i in range(len(decoded_words))]\n\n\t\tgen_eqn = [' '.join(words) for words in decoded_words]\n\t\t\n\t\tquestions \t+= ques\n\t\tact_eqns\t+= eqn\n\t\tgen_eqns\t+= gen_eqn\n\t\tscores\t\t+= correct_or_not\n\t\tconfs\t\t+= list(confidence)\n\t\tbatch_num\t+= 1\n\t\tprint(\"Completed {} / {}...\".format(batch_num, total_batches), end = '\\r', flush = True)\n\n\tresults_df = pd.DataFrame([questions, act_eqns, gen_eqns, scores, confs]).transpose()\n\tresults_df.columns = ['Question', 'Actual Equation', 'Generated Equation', 'Score', 'Confidence']\n\tif config.conf != 'similarity':\n\t\tcsv_file_path = os.path.join('ConfidenceEstimates',config.dataset + '_' + config.run_name + '_' + config.conf + '.csv')\n\telse:\n\t\tcsv_file_path = os.path.join('ConfidenceEstimates',config.dataset + '_' + config.run_name + '_' + config.conf + '_' + config.sim_criteria + '.csv')\n\tresults_df.to_csv(csv_file_path)\n\tlogger.info(\"Done in {} seconds\".format(time() - start))\n\ndef get_hiddens(config, model, val_dataloader, voc1, voc2, device):\n\tbatch_num =1\n\t\n\tmodel.eval()\n\n\thiddens = []\n\toperands = []\n\n\tfor data in val_dataloader:\n\t\tif len(data['ques']) == config.batch_size:\n\t\t\tsent1s = sents_to_idx(voc1, data['ques'], config.max_length)\n\t\t\tsent2s = sents_to_idx(voc2, data['eqn'], config.max_length)\n\t\t\tnums = data['nums']\n\t\t\tans = data['ans']\n\n\t\t\tques = data['ques']\n\n\t\t\tsent1_var, sent2_var, input_len1, input_len2 = process_batch(sent1s, sent2s, voc1, voc2, device)\n\n\t\t\thidden, decoder_output = model.obtain_hidden(config, ques, sent1_var, sent2_var, input_len1, input_len2)\n\n\t\t\tinfix = get_infix_eq(decoder_output, nums)[0] # WORKS ONLY FOR BATCH SIZE 1\n\t\t\twords = infix.split()\n\n\t\t\ttype_rep = []\n\t\t\toperand_types = []\n\n\t\t\tfor w in range(len(words)):\n\t\t\t\tif words[w] == '/':\n\t\t\t\t\tif words[w-1][0] == 'n':\n\t\t\t\t\t\toperand_types.append(['dividend', words[w-1]])\n\t\t\t\t\tif words[w+1][0] == 'n':\n\t\t\t\t\t\toperand_types.append(['divisor', words[w+1]])\n\t\t\t\telif words[w] == '-':\n\t\t\t\t\tif words[w-1][0] == 'n':\n\t\t\t\t\t\toperand_types.append(['minuend', words[w-1]])\n\t\t\t\t\tif words[w+1][0] == 'n':\n\t\t\t\t\t\toperand_types.append(['subtrahend', words[w+1]])\n\n\t\t\tfor z in range(len(operand_types)):\n\t\t\t\tentity = operand_types[z][1]\n\t\t\t\tfor y in range(len(hidden)):\n\t\t\t\t\tif hidden[y][0] == entity:\n\t\t\t\t\t\ttype_rep.append([operand_types[z][0], hidden[y][1]])\n\n\t\t\thiddens = hiddens + hidden\n\t\t\toperands = operands + type_rep\n\n\treturn hiddens, operands","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:31:09.542525Z","iopub.execute_input":"2024-11-13T06:31:09.542978Z","iopub.status.idle":"2024-11-13T06:31:09.673908Z","shell.execute_reply.started":"2024-11-13T06:31:09.542932Z","shell.execute_reply":"2024-11-13T06:31:09.673046Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## main.py","metadata":{}},{"cell_type":"code","source":"global log_folder\nglobal model_folder\nglobal result_folder\nglobal data_path\nglobal board_path\n\nlog_folder = 'logs'\nmodel_folder = 'models'\noutputs_folder = 'outputs'\nresult_folder = './out/'\ndata_path = '/kaggle/input/svamp-dataset/data/'\nboard_path = './runs/'\n\ndef load_data(config, logger):\n\t'''\n\t\tLoads the data from the datapath in torch dataset form\n\n\t\tArgs:\n\t\t\tconfig (dict) : configuration/args\n\t\t\tlogger (logger) : logger object for logging\n\n\t\tReturns:\n\t\t\tdataloader(s) \n\t'''\n\tif config.mode == 'train':\n\t\tlogger.debug('Loading Training Data...')\n\n\t\t'''Load Datasets'''\n\t\ttrain_set = TextDataset(data_path=data_path, dataset=config.dataset,\n\t\t\t\t\t\t\t\tdatatype='train', max_length=config.max_length, is_debug=config.debug)\n\t\tval_set = TextDataset(data_path=data_path, dataset=config.dataset,  datatype='dev', max_length=config.max_length, \n\t\t\t\t\t\t\t\tis_debug=config.debug, grade_info=config.grade_disp, type_info=config.type_disp, \n\t\t\t\t\t\t\t\tchallenge_info=config.challenge_disp)\n\t\t\n\t\t'''In case of sort by length, write a different case with shuffle=False '''\n\t\ttrain_dataloader = DataLoader(\n\t\t\ttrain_set, batch_size=config.batch_size, shuffle=True, num_workers=5)\n\t\tval_dataloader = DataLoader(\n\t\t\tval_set, batch_size=config.batch_size, shuffle=True, num_workers=5)\n\n\t\ttrain_size = len(train_dataloader) * config.batch_size\n\t\tval_size = len(val_dataloader)* config.batch_size\n\t\t\n\t\tmsg = 'Training and Validation Data Loaded:\\nTrain Size: {}\\nVal Size: {}'.format(train_size, val_size)\n\t\tlogger.info(msg)\n\n\t\treturn train_dataloader, val_dataloader\n\n\telif config.mode == 'test' or config.mode == 'conf':\n\t\tlogger.debug('Loading Test Data...')\n\n\t\ttest_set = TextDataset(data_path=data_path, dataset=config.dataset,\n\t\t\t\t\t\t\t   datatype='test', max_length=config.max_length, is_debug=config.debug)\n\t\ttest_dataloader = DataLoader(\n\t\t\ttest_set, batch_size=config.batch_size, shuffle=True, num_workers=5)\n\n\t\tlogger.info('Test Data Loaded...')\n\t\treturn test_dataloader\n\n\telse:\n\t\tlogger.critical('Invalid Mode Specified')\n\t\traise Exception('{} is not a valid mode'.format(config.mode))\n\n\nkaggle_args = {\n    'mode': 'train',\n    'gpu': 0,\n    'embedding': 'bert',\n    'emb_name': 'bert-base-uncased',\n    'emb1_size': 768,\n    'hidden_size': 32,\n    'depth': 1,\n    'lr': 0.0002,\n    'emb_lr': 8e-6,\n    'batch_size': 16,\n    'epochs': 10,\n    'dataset': 'mawps-asdiv-a_svamp',\n    'full_cv': False,\n    'run_name': 'run_mawps-asdiv-a',\n}\n\n\n# def main():\n# \t'''read arguments'''\n# \tparser = build_parser()\n# \targs = parser.parse_args()\n# \tconfig = args\n# \tmode = config.mode\n# \tif mode == 'train':\n# \t\tis_train = True\n# \telse:\n# \t\tis_train = False\n\n# \t''' Set seed for reproducibility'''\n# \tnp.random.seed(config.seed)\n# \ttorch.manual_seed(config.seed)\n# \trandom.seed(config.seed)\n\n# \t'''GPU initialization'''\n# \tdevice = gpu_init_pytorch(config.gpu)\n\nconfig =  parse_arguments(kaggle_args)\n\nmode = config.mode\nif mode == 'train':\n    is_train = True\nelse:\n    is_train = False\n\n''' Set seed for reproducibility'''\nnp.random.seed(config.seed)\ntorch.manual_seed(config.seed)\nrandom.seed(config.seed)\n\n'''GPU initialization'''\ndevice = gpu_init_pytorch(config.gpu)\n# device = torch.device('cpu')\n\nif config.full_cv:\n    global data_path \n    data_name = config.dataset\n    data_path = data_path + data_name + '/'\n    config.val_result_path = os.path.join(result_folder, 'CV_results_{}.json'.format(data_name))\n    fold_acc_score = 0.0\n    folds_scores = []\n    for z in range(5):\n        run_name = config.run_name + '_fold' + str(z)\n        config.dataset = 'fold' + str(z)\n        config.log_path = os.path.join(log_folder, run_name)\n        config.model_path = os.path.join(model_folder, run_name)\n        config.board_path = os.path.join(board_path, run_name)\n        config.outputs_path = os.path.join(outputs_folder, run_name)\n\n        vocab1_path = os.path.join(config.model_path, 'vocab1.p')\n        vocab2_path = os.path.join(config.model_path, 'vocab2.p')\n        config_file = os.path.join(config.model_path, 'config.p')\n        log_file = os.path.join(config.log_path, 'log.txt')\n\n        if config.results:\n            config.result_path = os.path.join(result_folder, 'val_results_{}_{}.json'.format(data_name, config.dataset))\n\n        if is_train:\n            create_save_directories(config.log_path)\n            create_save_directories(config.model_path)\n            create_save_directories(config.outputs_path)\n        else:\n            create_save_directories(config.log_path)\n            create_save_directories(config.result_path)\n\n        logger = get_logger(run_name, log_file, logging.DEBUG)\n        writer = SummaryWriter(config.board_path)\n\n        logger.debug('Created Relevant Directories')\n        logger.info('Experiment Name: {}'.format(config.run_name))\n\n        '''Read Files and create/load Vocab'''\n        if is_train:\n            train_dataloader, val_dataloader = load_data(config, logger)\n\n            logger.debug('Creating Vocab...')\n\n            voc1 = Voc1()\n            voc1.create_vocab_dict(config, train_dataloader)\n\n            # To Do : Remove Later\n            voc1.add_to_vocab_dict(config, val_dataloader)\n\n            voc2 = Voc2(config)\n            voc2.create_vocab_dict(config, train_dataloader)\n\n            # To Do : Remove Later\n            voc2.add_to_vocab_dict(config, val_dataloader)\n\n            logger.info(\n                'Vocab Created with number of words : {}'.format(voc1.nwords))\n\n            with open(vocab1_path, 'wb') as f:\n                pickle.dump(voc1, f, protocol=pickle.HIGHEST_PROTOCOL)\n            with open(vocab2_path, 'wb') as f:\n                pickle.dump(voc2, f, protocol=pickle.HIGHEST_PROTOCOL)\n\n            logger.info('Vocab saved at {}'.format(vocab1_path))\n\n        else:\n            test_dataloader = load_data(config, logger)\n            logger.info('Loading Vocab File...')\n\n            with open(vocab1_path, 'rb') as f:\n                voc1 = pickle.load(f)\n            with open(vocab2_path, 'rb') as f:\n                voc2 = pickle.load(f)\n\n            logger.info('Vocab Files loaded from {}\\nNumber of Words: {}'.format(vocab1_path, voc1.nwords))\n\n        checkpoint = get_latest_checkpoint(config.model_path, logger)\n\n        if is_train:\n            model = build_model(config=config, voc1=voc1, voc2=voc2, device=device, logger=logger, num_iters=len(train_dataloader))\n\n            logger.info('Initialized Model')\n            \n            if checkpoint == None:\n                min_val_loss = torch.tensor(float('inf')).item()\n                min_train_loss = torch.tensor(float('inf')).item()\n                max_val_bleu = 0.0\n                max_val_acc = 0.0\n                max_train_acc = 0.0\n                best_epoch = 0\n                epoch_offset = 0\n            else:\n                epoch_offset, min_train_loss, min_val_loss, max_train_acc, max_val_acc, max_val_bleu, best_epoch, voc1, voc2 = load_checkpoint(config, model, config.mode, checkpoint, logger, device)\n\n            with open(config_file, 'wb') as f:\n                pickle.dump(vars(config), f, protocol=pickle.HIGHEST_PROTOCOL)\n\n            logger.debug('Config File Saved')\n\n            logger.info('Starting Training Procedure')\n            max_val_acc = train_model(model, train_dataloader, val_dataloader, voc1, voc2,\n                        device, config, logger, epoch_offset, min_val_loss, max_val_bleu, max_val_acc, min_train_loss, max_train_acc, best_epoch, writer)\n\n        else:\n            gpu = config.gpu\n\n            with open(config_file, 'rb') as f:\n                config = AttrDict(pickle.load(f))\n                config.gpu = gpu\n\n            model = build_model(config=config, voc1=voc1, voc2=voc2, device=device, logger=logger)\n\n            epoch_offset, min_train_loss, min_val_loss, max_train_acc, max_val_acc, max_val_bleu, best_epoch, voc1, voc2 = load_checkpoint(config, model, config.mode, checkpoint, logger, device)\n\n            logger.info('Prediction from')\n            od = OrderedDict()\n            od['epoch'] = epoch_offset\n            od['min_train_loss'] = min_train_loss\n            od['min_val_loss'] = min_val_loss\n            od['max_train_acc'] = max_train_acc\n            od['max_val_acc'] = max_val_acc\n            od['max_val_bleu'] = max_val_bleu\n            od['best_epoch'] = best_epoch\n            print_log(logger, od)\n\n            test_acc_epoch, test_loss_epoch = run_validation(config, model, test_dataloader, voc1, voc2, device, logger)\n            logger.info('Accuracy: {} \\t Loss: {}'.format(test_acc_epoch, test_loss_epoch))\n\n        fold_acc_score += max_val_acc\n        folds_scores.append(max_val_acc)\n\n    fold_acc_score = fold_acc_score/5\n    store_val_results(config, fold_acc_score, folds_scores)\n    logger.info('Final Val score: {}'.format(fold_acc_score))\n        \n\nelse:\n    '''Run Config files/paths'''\n    run_name = config.run_name\n    config.log_path = os.path.join(log_folder, run_name)\n    config.model_path = os.path.join(model_folder, run_name)\n    config.board_path = os.path.join(board_path, run_name)\n    config.outputs_path = os.path.join(outputs_folder, run_name)\n\n    vocab1_path = os.path.join(config.model_path, 'vocab1.p')\n    vocab2_path = os.path.join(config.model_path, 'vocab2.p')\n    config_file = os.path.join(config.model_path, 'config.p')\n    log_file = os.path.join(config.log_path, 'log.txt')\n\n    if config.results:\n        config.result_path = os.path.join(result_folder, 'val_results_{}.json'.format(config.dataset))\n\n    if is_train:\n        create_save_directories(config.log_path)\n        create_save_directories(config.model_path)\n        create_save_directories(config.outputs_path)\n    else:\n        create_save_directories(config.log_path)\n        create_save_directories(config.result_path)\n\n    logger = get_logger(run_name, log_file, logging.DEBUG)\n    writer = SummaryWriter(config.board_path)\n\n    logger.debug('Created Relevant Directories')\n    logger.info('Experiment Name: {}'.format(config.run_name))\n\n    '''Read Files and create/load Vocab'''\n    if is_train:\n        train_dataloader, val_dataloader = load_data(config, logger)\n\n        logger.debug('Creating Vocab...')\n\n        voc1 = Voc1()\n        voc1.create_vocab_dict(config, train_dataloader)\n\n        # To Do : Remove Later\n        voc1.add_to_vocab_dict(config, val_dataloader)\n\n        voc2 = Voc2(config)\n        voc2.create_vocab_dict(config, train_dataloader)\n\n        # To Do : Remove Later\n        voc2.add_to_vocab_dict(config, val_dataloader)\n\n        logger.info(\n            'Vocab Created with number of words : {}'.format(voc1.nwords))\n\n        with open(vocab1_path, 'wb') as f:\n            pickle.dump(voc1, f, protocol=pickle.HIGHEST_PROTOCOL)\n        with open(vocab2_path, 'wb') as f:\n            pickle.dump(voc2, f, protocol=pickle.HIGHEST_PROTOCOL)\n\n        logger.info('Vocab saved at {}'.format(vocab1_path))\n\n    else:\n        test_dataloader = load_data(config, logger)\n        logger.info('Loading Vocab File...')\n\n        with open(vocab1_path, 'rb') as f:\n            voc1 = pickle.load(f)\n        with open(vocab2_path, 'rb') as f:\n            voc2 = pickle.load(f)\n\n        logger.info('Vocab Files loaded from {}\\nNumber of Words: {}'.format(vocab1_path, voc1.nwords))\n\n    checkpoint = get_latest_checkpoint(config.model_path, logger)\n\n    if is_train:\n        model = build_model(config=config, voc1=voc1, voc2=voc2, device=device, logger=logger, num_iters=len(train_dataloader))\n\n        logger.info('Initialized Model')\n        \n        if checkpoint == None:\n            min_val_loss = torch.tensor(float('inf')).item()\n            min_train_loss = torch.tensor(float('inf')).item()\n            max_val_bleu = 0.0\n            max_val_acc = 0.0\n            max_train_acc = 0.0\n            best_epoch = 0\n            epoch_offset = 0\n        else:\n            epoch_offset, min_train_loss, min_val_loss, max_train_acc, max_val_acc, max_val_bleu, best_epoch, voc1, voc2 = load_checkpoint(config, model, config.mode, checkpoint, logger, device)\n\n        with open(config_file, 'wb') as f:\n            pickle.dump(vars(config), f, protocol=pickle.HIGHEST_PROTOCOL)\n\n        logger.debug('Config File Saved')\n\n        logger.info('Starting Training Procedure')\n        train_model(model, train_dataloader, val_dataloader, voc1, voc2,\n                    device, config, logger, epoch_offset, min_val_loss, max_val_bleu, max_val_acc, min_train_loss, max_train_acc, best_epoch, writer)\n\n    else :\n        gpu = config.gpu\n        conf = config.conf\n        sim_criteria = config.sim_criteria\n        adv = config.adv\n        mode = config.mode\n        dataset = config.dataset\n        batch_size = config.batch_size\n        with open(config_file, 'rb') as f:\n            config = AttrDict(pickle.load(f))\n            config.gpu = gpu\n            config.conf = conf\n            config.sim_criteria = sim_criteria\n            config.adv = adv\n            config.mode = mode\n            config.dataset = dataset\n            config.batch_size = batch_size\n\n        model = build_model(config=config, voc1=voc1, voc2=voc2, device=device, logger=logger,num_iters=len(test_dataloader))\n\n        epoch_offset, min_train_loss, min_val_loss, max_train_acc, max_val_acc, max_val_bleu, best_epoch, voc1, voc2 = load_checkpoint(config, model, config.mode, checkpoint, logger, device)\n\n        logger.info('Prediction from')\n        od = OrderedDict()\n        od['epoch'] = epoch_offset\n        od['min_train_loss'] = min_train_loss\n        od['min_val_loss'] = min_val_loss\n        od['max_train_acc'] = max_train_acc\n        od['max_val_acc'] = max_val_acc\n        od['max_val_bleu'] = max_val_bleu\n        od['best_epoch'] = best_epoch\n        print_log(logger, od)\n\n        if config.mode == 'test':\n            test_acc_epoch = run_validation(config, model, test_dataloader, voc1, voc2, device, logger, 0)\n            logger.info('Accuracy: {}'.format(test_acc_epoch))\n        else:\n            estimate_confidence(config, model, test_dataloader, logger)\n\n\n''' Just docstring format '''\n# class Vehicles(object):\n# \t'''\n# \tThe Vehicle object contains a lot of vehicles\n\n# \tArgs:\n# \t\targ (str): The arg is used for...\n# \t\t*args: The variable arguments are used for...\n# \t\t**kwargs: The keyword arguments are used for...\n\n# \tAttributes:\n# \t\targ (str): This is where we store arg,\n# \t'''\n# \tdef __init__(self, arg, *args, **kwargs):\n# \t\tself.arg = arg\n\n# \tdef cars(self, distance,destination):\n# \t\t'''We can't travel distance in vehicles without fuels, so here is the fuels\n\n# \t\tArgs:\n# \t\t\tdistance (int): The amount of distance traveled\n# \t\t\tdestination (bool): Should the fuels refilled to cover the distance?\n\n# \t\tRaises:\n# \t\t\tRuntimeError: Out of fuel\n\n# \t\tReturns:\n# \t\t\tcars: A car mileage\n# \t\t'''\n# \t\tpass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:31:09.676210Z","iopub.execute_input":"2024-11-13T06:31:09.676826Z","iopub.status.idle":"2024-11-13T06:39:38.775629Z","shell.execute_reply.started":"2024-11-13T06:31:09.676761Z","shell.execute_reply":"2024-11-13T06:39:38.769377Z"}},"outputs":[{"name":"stderr","text":"2024-11-13 06:31:09,800 | DEBUG | 608083207.py: 282 : <module>() ::\t Created Relevant Directories\n2024-11-13 06:31:09,801 | INFO | 608083207.py: 283 : <module>() ::\t Experiment Name: run_mawps-asdiv-a\n2024-11-13 06:31:09,803 | DEBUG | 608083207.py: 26 : load_data() ::\t Loading Training Data...\n2024-11-13 06:31:09,892 | INFO | 608083207.py: 45 : load_data() ::\t Training and Validation Data Loaded:\nTrain Size: 3152\nVal Size: 1008\n2024-11-13 06:31:09,893 | DEBUG | 608083207.py: 289 : <module>() ::\t Creating Vocab...\n2024-11-13 06:31:11,376 | INFO | 608083207.py: 303 : <module>() ::\t Vocab Created with number of words : 4086\n2024-11-13 06:31:11,381 | INFO | 608083207.py: 311 : <module>() ::\t Vocab saved at models/run_mawps-asdiv-a/vocab1.p\n2024-11-13 06:31:11,384 | WARNING | 1263929403.py: 340 : get_latest_checkpoint() ::\t No Checkpoints Found\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb62fcf576e3428dad276818df8475f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a492c3290ea435a80ce513e9f3aaf6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbcd6ae0d5c74a4ca17721f09f13a964"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c94e8b38810f41c9ad17f27867894ed6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbddd690676b4c3386f465cf8c45622a"}},"metadata":{}},{"name":"stderr","text":"2024-11-13 06:31:15,503 | DEBUG | 1800631669.py: 30 : __init__() ::\t Building Encoders...\n2024-11-13 06:31:15,506 | DEBUG | 1800631669.py: 40 : __init__() ::\t Encoders Built...\n2024-11-13 06:31:15,724 | DEBUG | 1800631669.py: 58 : __init__() ::\t Decoder RNN Built...\n2024-11-13 06:31:15,725 | DEBUG | 1800631669.py: 60 : __init__() ::\t Initalizing Optimizer and Criterion...\n2024-11-13 06:31:16,247 | INFO | 1800631669.py: 66 : __init__() ::\t All Model Components Initialized...\n2024-11-13 06:31:16,406 | INFO | 608083207.py: 329 : <module>() ::\t Initialized Model\n2024-11-13 06:31:16,408 | DEBUG | 608083207.py: 345 : <module>() ::\t Config File Saved\n2024-11-13 06:31:16,409 | INFO | 608083207.py: 347 : <module>() ::\t Starting Training Procedure\n2024-11-13 06:31:16,409 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 1\t\n","output_type":"stream"},{"name":"stdout","text":"Completed 198 / 197...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:32:00,344 | DEBUG | 1800631669.py: 387 : train_model() ::\t Training for epoch 1 completed...\nTime Taken: 0.732231871287028\n2024-11-13 06:32:00,345 | DEBUG | 1800631669.py: 388 : train_model() ::\t Starting Validation\n","output_type":"stream"},{"name":"stdout","text":"Completed 64 / 63...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:32:06,152 | DEBUG | 1800631669.py: 451 : train_model() ::\t Validation Bleu: 0.041950664976199425\n2024-11-13 06:32:06,154 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 1\t\n best epoch: 1\t\n train loss epoch: 1.8216053686166167\t\n min train loss: 1.8216053686166167\t\n val loss epoch: 1.3512272834777832\t\n min val loss: 1.3512272834777832\t\n train acc epoch: 0.0038240917782026767\t\n max train acc: 0.0038240917782026767\t\n val acc epoch: 0.019\t\n max val acc: 0.019\t\n val bleu epoch: (0.041950664976199425, [0.4692928039702233, 0.1758093525179856, 0.011437908496732025, 0.004464285714285714], 0.925961078642316, 0.9285714285714286, 3224, 3472)\t\n max val bleu: 0.041950664976199425\t\n2024-11-13 06:32:06,155 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 2\t\n","output_type":"stream"},{"name":"stdout","text":"Completed 198 / 197...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:32:49,851 | DEBUG | 1800631669.py: 387 : train_model() ::\t Training for epoch 2 completed...\nTime Taken: 0.7282628417015076\n2024-11-13 06:32:49,853 | DEBUG | 1800631669.py: 388 : train_model() ::\t Starting Validation\n","output_type":"stream"},{"name":"stdout","text":"Completed 64 / 63...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:32:55,772 | DEBUG | 1800631669.py: 451 : train_model() ::\t Validation Bleu: 0.07786075434629645\n2024-11-13 06:32:55,774 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 2\t\n best epoch: 2\t\n train loss epoch: 0.9385045495735205\t\n min train loss: 0.9385045495735205\t\n val loss epoch: 1.352889060974121\t\n min val loss: 1.3512272834777832\t\n train acc epoch: 0.07520713830465264\t\n max train acc: 0.07520713830465264\t\n val acc epoch: 0.097\t\n max val acc: 0.097\t\n val bleu epoch: (0.07786075434629645, [0.5329015544041451, 0.21888111888111889, 0.06774193548387097, 0.004651162790697674], 1.0, 1.1117511520737327, 3860, 3472)\t\n max val bleu: 0.07786075434629645\t\n2024-11-13 06:32:55,775 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 3\t\n","output_type":"stream"},{"name":"stdout","text":"Completed 198 / 197...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:33:39,453 | DEBUG | 1800631669.py: 387 : train_model() ::\t Training for epoch 3 completed...\nTime Taken: 0.7279536326726278\n2024-11-13 06:33:39,454 | DEBUG | 1800631669.py: 388 : train_model() ::\t Starting Validation\n","output_type":"stream"},{"name":"stdout","text":"Completed 64 / 63...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:33:45,352 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 3\t\n best epoch: 2\t\n train loss epoch: 0.76331804160741\t\n min train loss: 0.76331804160741\t\n val loss epoch: 1.4096343517303467\t\n min val loss: 1.3512272834777832\t\n train acc epoch: 0.1864244741873805\t\n max train acc: 0.1864244741873805\t\n val acc epoch: 0.071\t\n max val acc: 0.097\t\n val bleu epoch: (0.13986316548650085, [0.5549464891673193, 0.24019780996114448, 0.09175314036045877, 0.031287605294825514], 1.0, 1.1033986175115207, 3831, 3472)\t\n max val bleu: 0.13986316548650085\t\n2024-11-13 06:33:45,354 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 4\t\n","output_type":"stream"},{"name":"stdout","text":"Completed 198 / 197...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:34:29,379 | DEBUG | 1800631669.py: 387 : train_model() ::\t Training for epoch 4 completed...\nTime Taken: 0.7337372779846192\n2024-11-13 06:34:29,380 | DEBUG | 1800631669.py: 388 : train_model() ::\t Starting Validation\n","output_type":"stream"},{"name":"stdout","text":"Completed 64 / 63...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:34:35,275 | DEBUG | 1800631669.py: 451 : train_model() ::\t Validation Bleu: 0.21721169625299092\n2024-11-13 06:34:35,276 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 4\t\n best epoch: 4\t\n train loss epoch: 0.6484532599420921\t\n min train loss: 0.6484532599420921\t\n val loss epoch: 1.5208244323730469\t\n min val loss: 1.3512272834777832\t\n train acc epoch: 0.21924792861695347\t\n max train acc: 0.21924792861695347\t\n val acc epoch: 0.13\t\n max val acc: 0.13\t\n val bleu epoch: (0.21721169625299092, [0.6536267318663407, 0.29317418873554646, 0.1588340273646639, 0.07313642756680731], 1.0, 1.0601958525345623, 3681, 3472)\t\n max val bleu: 0.21721169625299092\t\n2024-11-13 06:34:35,277 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 5\t\n","output_type":"stream"},{"name":"stdout","text":"Completed 198 / 197...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:35:19,090 | DEBUG | 1800631669.py: 387 : train_model() ::\t Training for epoch 5 completed...\nTime Taken: 0.73020920753479\n2024-11-13 06:35:19,091 | DEBUG | 1800631669.py: 388 : train_model() ::\t Starting Validation\n","output_type":"stream"},{"name":"stdout","text":"Completed 64 / 63...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:35:24,991 | DEBUG | 1800631669.py: 451 : train_model() ::\t Validation Bleu: 0.2088831246584926\n2024-11-13 06:35:24,993 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 5\t\n best epoch: 5\t\n train loss epoch: 0.5480420403875873\t\n min train loss: 0.5480420403875873\t\n val loss epoch: 1.539286494255066\t\n min val loss: 1.3512272834777832\t\n train acc epoch: 0.29891650732950925\t\n max train acc: 0.29891650732950925\t\n val acc epoch: 0.144\t\n max val acc: 0.144\t\n val bleu epoch: (0.2088831246584926, [0.6681187040566294, 0.29031051253273477, 0.15481171548117154, 0.06340057636887608], 1.0, 1.0578917050691243, 3673, 3472)\t\n max val bleu: 0.21721169625299092\t\n2024-11-13 06:35:24,994 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 6\t\n","output_type":"stream"},{"name":"stdout","text":"Completed 198 / 197...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:36:08,688 | DEBUG | 1800631669.py: 387 : train_model() ::\t Training for epoch 6 completed...\nTime Taken: 0.7282268325487773\n2024-11-13 06:36:08,689 | DEBUG | 1800631669.py: 388 : train_model() ::\t Starting Validation\n","output_type":"stream"},{"name":"stdout","text":"Completed 64 / 63...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:36:14,608 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 6\t\n best epoch: 5\t\n train loss epoch: 0.4803372976541923\t\n min train loss: 0.4803372976541923\t\n val loss epoch: 1.6790422201156616\t\n min val loss: 1.3512272834777832\t\n train acc epoch: 0.38209050350541746\t\n max train acc: 0.38209050350541746\t\n val acc epoch: 0.144\t\n max val acc: 0.144\t\n val bleu epoch: (0.20723081452645994, [0.6367157242447715, 0.2882004872955099, 0.15109450080085424, 0.0665163472378805], 1.0, 1.1154953917050692, 3873, 3472)\t\n max val bleu: 0.21721169625299092\t\n2024-11-13 06:36:14,609 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 7\t\n","output_type":"stream"},{"name":"stdout","text":"Completed 198 / 197...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:36:58,540 | DEBUG | 1800631669.py: 387 : train_model() ::\t Training for epoch 7 completed...\nTime Taken: 0.7321580330530802\n2024-11-13 06:36:58,541 | DEBUG | 1800631669.py: 388 : train_model() ::\t Starting Validation\n","output_type":"stream"},{"name":"stdout","text":"Completed 64 / 63...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:37:04,463 | DEBUG | 1800631669.py: 451 : train_model() ::\t Validation Bleu: 0.2171100797088928\n2024-11-13 06:37:04,465 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 7\t\n best epoch: 7\t\n train loss epoch: 0.4126153668372966\t\n min train loss: 0.4126153668372966\t\n val loss epoch: 1.874305248260498\t\n min val loss: 1.3512272834777832\t\n train acc epoch: 0.5159337157425111\t\n max train acc: 0.5159337157425111\t\n val acc epoch: 0.164\t\n max val acc: 0.164\t\n val bleu epoch: (0.2171100797088928, [0.6790874524714829, 0.29473684210526313, 0.16298200514138816, 0.06811145510835913], 1.0, 1.1362327188940091, 3945, 3472)\t\n max val bleu: 0.21721169625299092\t\n2024-11-13 06:37:04,466 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 8\t\n","output_type":"stream"},{"name":"stdout","text":"Completed 198 / 197...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:37:48,415 | DEBUG | 1800631669.py: 387 : train_model() ::\t Training for epoch 8 completed...\nTime Taken: 0.7324669996897379\n2024-11-13 06:37:48,416 | DEBUG | 1800631669.py: 388 : train_model() ::\t Starting Validation\n","output_type":"stream"},{"name":"stdout","text":"Completed 64 / 63...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:37:54,336 | DEBUG | 1800631669.py: 451 : train_model() ::\t Validation Bleu: 0.24694598756551822\n2024-11-13 06:37:54,338 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 8\t\n best epoch: 8\t\n train loss epoch: 0.3618613374263502\t\n min train loss: 0.3618613374263502\t\n val loss epoch: 2.1334900856018066\t\n min val loss: 1.3512272834777832\t\n train acc epoch: 0.595602294455067\t\n max train acc: 0.595602294455067\t\n val acc epoch: 0.173\t\n max val acc: 0.173\t\n val bleu epoch: (0.24694598756551822, [0.6993911719939118, 0.31985044187627465, 0.1822863027806385, 0.0911983032873807], 1.0, 1.13536866359447, 3942, 3472)\t\n max val bleu: 0.24694598756551822\t\n2024-11-13 06:37:54,338 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 9\t\n","output_type":"stream"},{"name":"stdout","text":"Completed 198 / 197...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:38:38,063 | DEBUG | 1800631669.py: 387 : train_model() ::\t Training for epoch 9 completed...\nTime Taken: 0.7287348985671998\n2024-11-13 06:38:38,064 | DEBUG | 1800631669.py: 388 : train_model() ::\t Starting Validation\n","output_type":"stream"},{"name":"stdout","text":"Completed 64 / 63...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:38:44,028 | DEBUG | 1800631669.py: 451 : train_model() ::\t Validation Bleu: 0.21966874194480068\n2024-11-13 06:38:44,029 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 9\t\n best epoch: 9\t\n train loss epoch: 0.32177406593325164\t\n min train loss: 0.32177406593325164\t\n val loss epoch: 2.4282517433166504\t\n min val loss: 1.3512272834777832\t\n train acc epoch: 0.6539196940726577\t\n max train acc: 0.6539196940726577\t\n val acc epoch: 0.186\t\n max val acc: 0.186\t\n val bleu epoch: (0.21966874194480068, [0.6677933365523901, 0.3052196053469128, 0.16106442577030813, 0.07092819614711034], 1.0, 1.1929723502304148, 4142, 3472)\t\n max val bleu: 0.24694598756551822\t\n2024-11-13 06:38:44,030 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 10\t\n","output_type":"stream"},{"name":"stdout","text":"Completed 198 / 197...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:39:27,825 | DEBUG | 1800631669.py: 387 : train_model() ::\t Training for epoch 10 completed...\nTime Taken: 0.729901107152303\n2024-11-13 06:39:27,826 | DEBUG | 1800631669.py: 388 : train_model() ::\t Starting Validation\n","output_type":"stream"},{"name":"stdout","text":"Completed 64 / 63...\r","output_type":"stream"},{"name":"stderr","text":"2024-11-13 06:39:33,752 | DEBUG | 1800631669.py: 451 : train_model() ::\t Validation Bleu: 0.25750638756735006\n2024-11-13 06:39:33,753 | INFO | 1263929403.py: 572 : print_log() ::\t \n Epoch: 10\t\n best epoch: 10\t\n train loss epoch: 0.2877852454958026\t\n min train loss: 0.2877852454958026\t\n val loss epoch: 2.2794125080108643\t\n min val loss: 1.3512272834777832\t\n train acc epoch: 0.7029955385595921\t\n max train acc: 0.7029955385595921\t\n val acc epoch: 0.207\t\n max val acc: 0.207\t\n val bleu epoch: (0.25750638756735006, [0.7127551020408164, 0.33493150684931505, 0.20260416666666667, 0.09090909090909091], 1.0, 1.1290322580645162, 3920, 3472)\t\n max val bleu: 0.25750638756735006\t\n2024-11-13 06:39:33,754 | INFO | 1800631669.py: 490 : train_model() ::\t Training Completed for 10 epochs\n","output_type":"stream"},{"name":"stdout","text":"--Return--\nNone\n> \u001b[0;32m/tmp/ipykernel_30/1263929403.py\u001b[0m(617)\u001b[0;36mstore_results\u001b[0;34m()\u001b[0m\n\u001b[0;32m    615 \u001b[0;31m                        \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m--> 617 \u001b[0;31m                \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mstore_val_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  exit\n"}],"execution_count":7},{"cell_type":"code","source":"def generate_full_question(question, numbers):\n    for i, num in enumerate(numbers):\n        placeholder = f\"number{i}\"\n        question = question.replace(placeholder, str(num))\n    return question\n\ndef convert_eqn(equation, numbers):\n    for i, num in enumerate(numbers):\n        placeholder = f\"number{i}\"\n        equation = equation.replace(placeholder, str(num))\n    return equation\n\n# # Loop over the validation data\n# for data in val_dataloader:\n#     # Convert questions and equations to index representations\n#     sent1s = sents_to_idx(voc1, data['ques'], config.max_length)\n#     sent2s = sents_to_idx(voc2, data['eqn'], config.max_length)\n#     nums = data['nums']\n#     ans = data['ans']\n    \n#     # Optional configurations\n#     if config.grade_disp:\n#         grade = data['grade']\n#     if config.type_disp:\n#         type1 = data['type']\n#     if config.challenge_disp:\n#         type1 = data['type']\n#         var_type = data['var_type']\n#         annotator = data['annotator']\n#         alternate = data['alternate']\n    \n#     # Prepare data for the model\n#     ques = data['ques']\n#     sent1_var, sent2_var, input_len1, input_len2 = process_batch(sent1s, sent2s, voc1, voc2, device)\n    \n#     # Perform decoding\n#     val_loss, decoder_output, decoder_attn = model.greedy_decode(\n#         ques, sent1_var, sent2_var, input_len1, input_len2, validation=True\n#     )\n    \n#     # Prepare the expected and decoded outputs\n#     expected_outputs = data['eqn']\n#     decoded_outputs = [' '.join(output) for output in decoder_output]\n\n#     # Iterate over each entry in the batch and print the required information\n#     for i in range(len(ques)):\n#         # Retrieve question, expected equation, numbers, and decoder output\n#         question = ques[i]\n#         expected_eqn = expected_outputs[i]\n#         decoded_eqn = decoded_outputs[i]\n#         numbers = list(map(int, nums[i].split()))\n#         true_answer = ans[i].item()\n\n#         op = stack_to_string(decoder_output[i])\n#         num = nums[i].split()\n#         num = [float(nu) for nu in num]\n#         answer = ans[i].item()\n#         pred = ans_evaluator(op, num)\n        \n#         # decoded_corr, decoded_tot, decoded_disp_corr = cal_score(decoded_outputs[i], nums[i], ans)\n#         # print(decoded_corr)\n#         # Display computed results and comparison\n#         print(f\"Question {i+1}: {question}\")\n#         print(f\"converted Question {i+1}: { generate_full_question(question, numbers)}\")\n#         print(f\"Expected Equation: {expected_eqn}\")\n#         print(f\"converted exp Equation: {convert_eqn(expected_eqn, numbers)}\")\n#         print(f\"Decoded Equation: {decoded_eqn}\")\n#         print(f\"converted ded Equation: {convert_eqn(decoded_eqn, numbers)}\")\n#         print(f\"Numbers: {numbers}\")\n#         print(f\"True Answer: {true_answer}\")\n#         print(f\"Decoded Answer: {pred}\")\n#         print(\"-\" * 80)\n\n#     # Break after the first batch for demonstration\n#     break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:40:04.677022Z","iopub.execute_input":"2024-11-13T06:40:04.677447Z","iopub.status.idle":"2024-11-13T06:40:04.686925Z","shell.execute_reply.started":"2024-11-13T06:40:04.677394Z","shell.execute_reply":"2024-11-13T06:40:04.685860Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Function to write evaluation results into a file\ndef write_to_file(filename, data):\n    with open(filename, 'w') as f:\n        for line in data:\n            f.write(line + '\\n')\n\n# Loop over the validation data and collect output for file\noutput_lines = []\nfor data in val_dataloader:\n    # Convert questions and equations to index representations\n    sent1s = sents_to_idx(voc1, data['ques'], config.max_length)\n    sent2s = sents_to_idx(voc2, data['eqn'], config.max_length)\n    nums = data['nums']\n    ans = data['ans']\n    \n    # Prepare data for the model\n    ques = data['ques']\n    sent1_var, sent2_var, input_len1, input_len2 = process_batch(sent1s, sent2s, voc1, voc2, device)\n    \n    # Perform decoding\n    val_loss, decoder_output, decoder_attn = model.greedy_decode(\n        ques, sent1_var, sent2_var, input_len1, input_len2, validation=True\n    )\n    \n    # Iterate over each entry in the batch and collect the required information\n    for i in range(len(ques)):\n        # Retrieve question, expected equation, numbers, and decoder output\n        question = ques[i]\n        expected_eqn = data['eqn'][i]\n        decoded_eqn = ' '.join(decoder_output[i])  # Convert list to string format\n        numbers = list(map(int, nums[i].split()))\n        true_answer = ans[i].item()\n\n        # Convert the equation tokens and evaluate the decoded answer\n        op = stack_to_string(decoder_output[i])\n        num = [float(nu) for nu in nums[i].split()]\n        pred = ans_evaluator(op, num)\n        \n        # Generate the converted question and equations\n        converted_question = generate_full_question(question, numbers)\n        converted_expected_eqn = convert_eqn(expected_eqn, numbers)\n        converted_decoded_eqn = convert_eqn(decoded_eqn, numbers)\n\n        # Compare decoded answer with true answer\n        result_comparison = \"Correct\" if abs(pred - true_answer) <= 0.1 else \"Incorrect\"\n\n        # Prepare output for file\n        # output_lines.append(f\"Question {i+1}: {question}\")\n        output_lines.append(f\"Converted Question {i+1}: {converted_question}\")\n        # output_lines.append(f\"Expected Equation: {expected_eqn}\")\n        # output_lines.append(f\"Converted Expected Equation: {converted_expected_eqn}\")\n        # output_lines.append(f\"Decoded Equation: {decoded_eqn}\")\n        # output_lines.append(f\"Converted Decoded Equation: {converted_decoded_eqn}\")\n        # output_lines.append(f\"Numbers: {numbers}\")\n        output_lines.append(f\"True Answer: {true_answer}\")\n        output_lines.append(f\"Decoded Answer: {pred}\")\n        output_lines.append(f\"Predicted Result: {result_comparison}\")\n        output_lines.append(\"-\" * 80)\n\n\n# Write all collected lines to eval.txt\nwrite_to_file(\"eval.txt\", output_lines)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:40:05.346601Z","iopub.execute_input":"2024-11-13T06:40:05.347429Z","iopub.status.idle":"2024-11-13T06:40:10.454266Z","shell.execute_reply.started":"2024-11-13T06:40:05.347384Z","shell.execute_reply":"2024-11-13T06:40:10.453044Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import torch\ntorch.save(model, '/kaggle/working/entire_model.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:43:51.467061Z","iopub.execute_input":"2024-11-13T06:43:51.467498Z","iopub.status.idle":"2024-11-13T06:43:54.032649Z","shell.execute_reply.started":"2024-11-13T06:43:51.467453Z","shell.execute_reply":"2024-11-13T06:43:54.031797Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"!zip -r /kaggle/working/kaggle_working_dir.zip /kaggle/working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:45:03.108301Z","iopub.execute_input":"2024-11-13T06:45:03.109608Z","iopub.status.idle":"2024-11-13T06:46:05.040267Z","shell.execute_reply.started":"2024-11-13T06:45:03.109555Z","shell.execute_reply":"2024-11-13T06:46:05.039066Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/ (stored 0%)\n  adding: kaggle/working/eval.txt (deflated 85%)\n  adding: kaggle/working/models/ (stored 0%)\n  adding: kaggle/working/models/run_cv_asdiv-a_fold0/ (stored 0%)\n  adding: kaggle/working/models/run_cv_asdiv-a_fold0/vocab1.p (deflated 48%)\n  adding: kaggle/working/models/run_cv_asdiv-a_fold0/config.p (deflated 39%)\n  adding: kaggle/working/models/run_cv_asdiv-a_fold0/vocab2.p (deflated 28%)\n  adding: kaggle/working/models/run_mawps-asdiv-a/ (stored 0%)\n  adding: kaggle/working/models/run_mawps-asdiv-a/vocab1.p (deflated 50%)\n  adding: kaggle/working/models/run_mawps-asdiv-a/config.p (deflated 38%)\n  adding: kaggle/working/models/run_mawps-asdiv-a/vocab2.p (deflated 28%)\n  adding: kaggle/working/logs/ (stored 0%)\n  adding: kaggle/working/logs/run_cv_asdiv-a_fold0/ (stored 0%)\n  adding: kaggle/working/logs/run_cv_asdiv-a_fold0/log.txt (deflated 58%)\n  adding: kaggle/working/logs/run_mawps-asdiv-a/ (stored 0%)\n  adding: kaggle/working/logs/run_mawps-asdiv-a/log.txt (deflated 78%)\n  adding: kaggle/working/.virtual_documents/ (stored 0%)\n  adding: kaggle/working/runs/ (stored 0%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/ (stored 0%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731410226.c591521f96d0 (deflated 5%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731408123.01d5c98ec8be (deflated 5%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731408942.01d5c98ec8be (deflated 3%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731409242.01d5c98ec8be (deflated 5%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731407881.01d5c98ec8be (deflated 5%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731404853.01d5c98ec8be (deflated 5%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731407707.01d5c98ec8be (deflated 5%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731405414.01d5c98ec8be (deflated 5%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731404599.01d5c98ec8be (deflated 3%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731409408.01d5c98ec8be (deflated 5%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731409497.01d5c98ec8be (deflated 5%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731408557.01d5c98ec8be (deflated 5%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731405142.01d5c98ec8be (deflated 5%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731409473.01d5c98ec8be (deflated 5%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731406498.01d5c98ec8be (deflated 5%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731408453.01d5c98ec8be (deflated 5%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731408747.01d5c98ec8be (deflated 5%)\n  adding: kaggle/working/runs/run_cv_asdiv-a_fold0/events.out.tfevents.1731406746.01d5c98ec8be (deflated 5%)\n  adding: kaggle/working/runs/run_mawps-asdiv-a/ (stored 0%)\n  adding: kaggle/working/runs/run_mawps-asdiv-a/events.out.tfevents.1731433403.8842b6e32981 (deflated 5%)\n  adding: kaggle/working/runs/run_mawps-asdiv-a/events.out.tfevents.1731433344.8842b6e32981 (deflated 5%)\n  adding: kaggle/working/runs/run_mawps-asdiv-a/events.out.tfevents.1731430234.17eeb127b60f (stored 0%)\n  adding: kaggle/working/runs/run_mawps-asdiv-a/events.out.tfevents.1731479469.334b7efeaa7a (stored 0%)\n  adding: kaggle/working/runs/run_mawps-asdiv-a/events.out.tfevents.1731415855.fc8b46ef268f (deflated 5%)\n  adding: kaggle/working/runs/run_mawps-asdiv-a/events.out.tfevents.1731429435.ff220e0778c3 (deflated 5%)\n  adding: kaggle/working/runs/run_mawps-asdiv-a/events.out.tfevents.1731434075.8842b6e32981 (deflated 5%)\n  adding: kaggle/working/state.db (deflated 76%)\n  adding: kaggle/working/entire_model.pth (deflated 20%)\n  adding: kaggle/working/outputs/ (stored 0%)\n  adding: kaggle/working/outputs/run_cv_asdiv-a_fold0/ (stored 0%)\n  adding: kaggle/working/outputs/run_cv_asdiv-a_fold0/outputs.txt (deflated 86%)\n  adding: kaggle/working/outputs/run_cv_asdiv-a_fold0/attn.p (deflated 66%)\n  adding: kaggle/working/outputs/run_mawps-asdiv-a/ (stored 0%)\n  adding: kaggle/working/outputs/run_mawps-asdiv-a/outputs.txt (deflated 88%)\n  adding: kaggle/working/outputs/run_mawps-asdiv-a/attn.p (deflated 53%)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Create a link to the zip file\nFileLink(r'/kaggle/working/kaggle_working_dir.zip')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:50:35.409571Z","iopub.execute_input":"2024-11-13T06:50:35.410398Z","iopub.status.idle":"2024-11-13T06:50:35.416825Z","shell.execute_reply.started":"2024-11-13T06:50:35.410354Z","shell.execute_reply":"2024-11-13T06:50:35.415856Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/kaggle_working_dir.zip","text/html":"<a href='/kaggle/working/kaggle_working_dir.zip' target='_blank'>/kaggle/working/kaggle_working_dir.zip</a><br>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}